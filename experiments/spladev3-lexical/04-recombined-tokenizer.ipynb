{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import Dict, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_sparse_tools import convert_sparse_vector\n",
    "from remap_tokens import (\n",
    "    aggregate_weights,\n",
    "    calc_tf,\n",
    "    filter_list_tokens,\n",
    "    filter_pair_tokens,\n",
    "    reconstruct_bpe,\n",
    "    rescore_vector,\n",
    "    snowball_tokenize,\n",
    "    stem_list_tokens,\n",
    "    stem_pair_tokens,\n",
    ")\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "canonical_dataset_name = \"scifact\"\n",
    "dataset_name = \"scifact-bge-m3-sparse-vectors\"\n",
    "source_model = \"nirantk/splade-v3-lexical\"\n",
    "source_col_name = \"spalde-v3-lexical\"\n",
    "col_name = \"splade-snowball-rescore-large\"\n",
    "collection_name = f\"{dataset_name}-{col_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1009\": 0.20660123229026794, \"1011\": 0.036437395960092545, \"1013\": 0.05786345899105072, \"1014\": 0.5618454217910767, \"1017\": 0.12642613053321838, \"1018\": 0.06154331564903259, \"1020\": 0.00875066313892603, \"1022\": 0.0029254043474793434, \"1050\": 0.13071982562541962, \"1052\": 0.4093637466430664, \"1059\": 0.4673144817352295, \"2011\": 0.2652147710323334, \"2019\": 0.5381823778152466, \"2029\": 0.03925827145576477, \"2064\": 0.2539152204990387, \"2076\": 0.04394211992621422, \"2077\": 0.07884006202220917, \"2084\": 0.1510767638683319, \"2093\": 0.29473719000816345, \"2109\": 0.12470348179340363, \"2132\": 0.02887592278420925, \"2141\": 0.38374659419059753, \"2181\": 0.04394211992621422, \"2184\": 0.08782484382390976, \"2213\": 0.650757372379303, \"2220\": 0.6022219061851501, \"2240\": 0.5410289764404297, \"2243\": 0.7701805830001831, \"2287\": 0.401551216840744, \"2300\": 0.5506471395492554, \"2317\": 1.1381834745407104, \"2321\": 0.29619070887565613, \"2335\": 0.07341018319129944, \"2336\": 0.2637155055999756, \"2367\": 0.0029254043474793434, \"2402\": 0.22157983481884003, \"2415\": 0.05417001247406006, \"2430\": 0.6828403472900391, \"2440\": 0.6054253578186035, \"2458\": 0.8169882297515869, \"2459\": 0.2561853528022766, \"2475\": 0.5860490798950195, \"2484\": 0.39696553349494934, \"2504\": 0.05417001247406006, \"2512\": 0.020300358533859253, \"2515\": 0.14433705806732178, \"2522\": 0.47827014327049255, \"2529\": 0.6118015646934509, \"2542\": 0.052318159490823746, \"2570\": 0.2516399025917053, \"2575\": 0.4938860833644867, \"2654\": 0.41840189695358276, \"2655\": 0.6270449161529541, \"2689\": 0.058784693479537964, \"2714\": 0.6286086440086365, \"2720\": 0.12728634476661682, \"2744\": 0.5773153901100159, \"2752\": 0.1477125883102417, \"2764\": 0.24325250089168549, \"2765\": 0.3923587501049042, \"2775\": 0.42225050926208496, \"2812\": 0.24859806895256042, \"2817\": 0.16276304423809052, \"2819\": 0.5506471395492554, \"2846\": 0.23247487843036652, \"2864\": 0.0606246218085289, \"2881\": 0.012615402229130268, \"2891\": 0.4537591338157654, \"2896\": 0.30558720231056213, \"2904\": 0.06520967930555344, \"2913\": 0.09406650811433792, \"2944\": 0.14095009863376617, \"2951\": 0.5220900774002075, \"3020\": 0.34370049834251404, \"3029\": 0.5191890001296997, \"3041\": 0.21530038118362427, \"3043\": 1.1462857723236084, \"3170\": 0.45251765847206116, \"3210\": 0.11430477350950241, \"3231\": 0.2539152204990387, \"3252\": 0.10731173306703568, \"3273\": 0.21530038118362427, \"3334\": 0.8492490649223328, \"3336\": 0.7153595685958862, \"3367\": 0.083342544734478, \"3378\": 0.04207121208310127, \"3408\": 0.02316705882549286, \"3431\": 0.31489628553390503, \"3445\": 0.034552380442619324, \"3446\": 0.10379679501056671, \"3463\": 0.4812922179698944, \"3466\": 0.6769026517868042, \"3491\": 0.38441169261932373, \"3553\": 0.3339579105377197, \"3556\": 0.29400965571403503, \"3618\": 0.31489628553390503, \"3635\": 0.07068414986133575, \"3638\": 0.08961215615272522, \"3643\": 0.5729197263717651, \"3652\": 0.004870930220931768, \"3653\": 0.7881022095680237, \"3662\": 0.06977381557226181, \"3686\": 0.3588210940361023, \"3746\": 0.3077431619167328, \"3747\": 0.15777134895324707, \"3798\": 0.13157635927200317, \"3853\": 0.06520967930555344, \"3867\": 0.06337817758321762, \"3896\": 0.755608320236206, \"3917\": 0.07068414986133575, \"3929\": 0.12986256182193756, \"3943\": 0.11865071207284927, \"3972\": 0.7701805830001831, \"3981\": 0.1358480453491211, \"4008\": 0.22626367211341858, \"4017\": 0.40285754203796387, \"4094\": 0.4041621685028076, \"4102\": 0.5174443125724792, \"4106\": 0.7565253376960754, \"4114\": 0.21372433006763458, \"4146\": 0.016465263441205025, \"4162\": 0.5238267183303833, \"4167\": 1.117955207824707, \"4182\": 0.9440274834632874, \"4254\": 0.29619070887565613, \"4286\": 0.5290185213088989, \"4294\": 1.0526502132415771, \"4340\": 0.0174254160374403, \"4383\": 0.2969166338443756, \"4403\": 0.040196798741817474, \"4417\": 0.5979346632957458, \"4428\": 0.004870930220931768, \"4442\": 0.034552380442619324, \"4450\": 0.37371641397476196, \"4489\": 0.11517547070980072, \"4503\": 0.48610860109329224, \"4525\": 0.05417001247406006, \"4593\": 0.31560876965522766, \"4718\": 0.19220098853111267, \"4722\": 0.8074519634246826, \"4860\": 0.06154331564903259, \"4871\": 0.13925230503082275, \"4944\": 0.5882205963134766, \"4975\": 0.7220231294631958, \"5013\": 0.175953671336174, \"5105\": 0.13414156436920166, \"5169\": 0.06977381557226181, \"5244\": 0.05786345899105072, \"5300\": 0.5651806592941284, \"5360\": 0.6176109313964844, \"5387\": 0.11951763927936554, \"5393\": 0.3784096837043762, \"5443\": 0.18411032855510712, \"5468\": 0.777387797832489, \"5537\": 0.678390383720398, \"5546\": 0.08244366943836212, \"5593\": 0.23247487843036652, \"5604\": 0.20660123229026794, \"5609\": 0.08064348995685577, \"5644\": 0.17020416259765625, \"5646\": 0.2516399025917053, \"5700\": 0.40741631388664246, \"5705\": 0.21687394380569458, \"5710\": 0.8004589080810547, \"5717\": 0.30989447236061096, \"5761\": 0.5220900774002075, \"5769\": 0.495672345161438, \"5796\": 0.7782850861549377, \"5809\": 0.4158279001712799, \"5816\": 0.817850649356842, \"5852\": 0.03360854089260101, \"5890\": 0.20102575421333313, \"5966\": 0.401551216840744, \"6017\": 0.2990913391113281, \"6022\": 0.04953393340110779, \"6028\": 0.004870930220931768, \"6131\": 0.1477125883102417, \"6178\": 0.1602703034877777, \"6179\": 0.006812678650021553, \"6431\": 0.4818955361843109, \"6549\": 0.5995445251464844, \"6587\": 0.006812678650021553, \"6593\": 0.05786345899105072, \"6693\": 0.026025565341114998, \"6698\": 0.13243216276168823, \"6820\": 0.6573580503463745, \"6835\": 1.0668635368347168, \"6875\": 0.6022219061851501, \"6959\": 0.043007105588912964, \"6968\": 0.0354953333735466, \"7017\": 0.3910386264324188, \"7127\": 0.10818854719400406, \"7412\": 0.034552380442619324, \"7461\": 0.8272887468338013, \"7551\": 0.15023678541183472, \"7591\": 0.06246116757392883, \"7594\": 0.5540198087692261, \"7605\": 0.10906458646059036, \"7619\": 0.7333439588546753, \"7633\": 0.04953393340110779, \"7644\": 0.1751343309879303, \"7645\": 0.22782009840011597, \"7667\": 0.9013357162475586, \"7685\": 0.8941729068756104, \"7711\": 0.02887592278420925, \"7712\": 0.053244512528181076, \"7718\": 0.11430477350950241, \"7747\": 0.15442965924739838, \"7778\": 0.05417001247406006, \"7831\": 0.5197699069976807, \"7885\": 0.03925827145576477, \"7913\": 0.01934296265244484, \"7959\": 0.18978065252304077, \"8029\": 0.7009293437004089, \"8060\": 0.823009729385376, \"8092\": 0.2018241584300995, \"8123\": 0.053244512528181076, \"8153\": 0.1358480453491211, \"8160\": 0.2852376699447632, \"8185\": 0.3423145115375519, \"8292\": 0.31132611632347107, \"8329\": 0.10467668622732162, \"8360\": 0.7969439625740051, \"8776\": 0.669430673122406, \"8789\": 0.7647408246994019, \"9289\": 0.6583697199821472, \"9312\": 0.3601844012737274, \"9447\": 0.1401015669107437, \"9513\": 0.0038986403960734606, \"9539\": 0.05694137513637543, \"9556\": 0.20977331697940826, \"9560\": 0.013579257763922215, \"9617\": 0.04207121208310127, \"9646\": 0.3416208028793335, \"9651\": 0.04113444685935974, \"9700\": 0.0019512200960889459, \"9776\": 0.6613984704017639, \"9812\": 0.3170322775840759, \"9814\": 0.0058422754518687725, \"9854\": 0.23787821829319, \"9885\": 0.026976587250828743, \"10024\": 0.058784693479537964, \"10032\": 0.7755908370018005, \"10060\": 0.05970508232712746, \"10071\": 0.45251765847206116, \"10174\": 0.2622140049934387, \"10280\": 0.2409527748823166, \"10358\": 0.42353010177612305, \"10426\": 0.04674193635582924, \"10527\": 0.9108069539070129, \"10548\": 0.255429208278656, \"10640\": 0.07884006202220917, \"10726\": 0.3297532796859741, \"10768\": 0.07068414986133575, \"10834\": 0.7276995778083801, \"10857\": 0.05786345899105072, \"10903\": 0.46363574266433716, \"11062\": 0.12814582884311676, \"11137\": 0.6420594453811646, \"11156\": 0.030771657824516296, \"11207\": 0.09672962874174118, \"11234\": 0.2223619967699051, \"11326\": 0.036437395960092545, \"11477\": 0.47766464948654175, \"11487\": 0.053244512528181076, \"11627\": 0.018384648486971855, \"11643\": 0.053244512528181076, \"11667\": 0.19541899859905243, \"11709\": 0.18573370575904846, \"11728\": 0.021256839856505394, \"11791\": 0.08692999184131622, \"11917\": 1.001607894897461, \"11980\": 0.8517522215843201, \"12126\": 0.8057082891464233, \"12247\": 0.009718249551951885, \"12319\": 0.20580662786960602, \"12322\": 0.1011524572968483, \"12369\": 0.9052929878234863, \"12380\": 0.29255300760269165, \"12407\": 0.0174254160374403, \"12435\": 0.38041436672210693, \"12461\": 0.42608439922332764, \"12473\": 0.4617912769317627, \"12516\": 0.15275461971759796, \"12546\": 0.1751343309879303, \"12596\": 0.009718249551951885, \"12702\": 0.8161250352859497, \"12719\": 0.29981520771980286, \"12826\": 0.23556606471538544, \"13046\": 0.11604541540145874, \"13105\": 0.04860413447022438, \"13120\": 0.0038986403960734606, \"13181\": 0.8658194541931152, \"13221\": 0.09228714555501938, \"13296\": 0.16110190749168396, \"13531\": 0.5936289429664612, \"13594\": 0.7951818704605103, \"13597\": 0.7951818704605103, \"13599\": 0.3423145115375519, \"13722\": 0.49030399322509766, \"13908\": 0.736154317855835, \"13931\": 1.0116009712219238, \"14080\": 0.053244512528181076, \"14130\": 0.3077431619167328, \"14155\": 0.5957841277122498, \"14267\": 0.10818854719400406, \"14332\": 0.4512746334075928, \"14358\": 0.6613984704017639, \"14402\": 0.3777405619621277, \"14670\": 0.16524957120418549, \"14719\": 0.015504186972975731, \"15053\": 0.06520967930555344, \"15074\": 0.29619070887565613, \"15219\": 0.7898768186569214, \"15291\": 0.791648268699646, \"15329\": 0.08064348995685577, \"15698\": 0.05694137513637543, \"15756\": 0.34715715050697327, \"15758\": 0.06795065850019455, \"15822\": 0.4349733293056488, \"15868\": 0.020300358533859253, \"15871\": 0.08871890604496002, \"16014\": 0.1685553640127182, \"16058\": 0.37707099318504333, \"16216\": 0.6011518239974976, \"16231\": 0.6892333030700684, \"16268\": 0.018384648486971855, \"16289\": 0.1384023278951645, \"16330\": 0.08513788133859634, \"16381\": 0.010684899985790253, \"16463\": 0.0029254043474793434, \"16478\": 0.16110190749168396, \"16492\": 0.18167030811309814, \"16578\": 0.11081436276435852, \"16662\": 0.7934166193008423, \"16705\": 0.8682814836502075, \"16725\": 0.9379299283027649, \"16853\": 0.4151833653450012, \"16940\": 0.0606246218085289, \"17011\": 0.6941232681274414, \"17132\": 0.5151132941246033, \"17208\": 0.3897167444229126, \"17431\": 0.007782140281051397, \"17463\": 0.05139094591140747, \"17706\": 0.1889725625514984, \"17819\": 0.022212404757738113, \"17826\": 0.06977381557226181, \"17908\": 0.5324648022651672, \"18075\": 0.08513788133859634, \"18215\": 0.9240728616714478, \"18234\": 0.07612881064414978, \"18250\": 0.06246116757392883, \"18269\": 1.0999135971069336, \"18349\": 0.016465263441205025, \"18419\": 0.30558720231056213, \"18422\": 0.46608972549438477, \"18439\": 1.0992631912231445, \"18585\": 0.011650617234408855, \"18749\": 0.23247487843036652, \"18809\": 0.8780695199966431, \"19037\": 0.2983669638633728, \"19064\": 1.072225570678711, \"19124\": 0.05139094591140747, \"19199\": 0.26820653676986694, \"19209\": 0.23787821829319, \"19241\": 1.4812493324279785, \"19362\": 0.43938836455345154, \"19565\": 0.9658246636390686, \"19761\": 0.07612881064414978, \"19879\": 0.036437395960092545, \"20062\": 0.6096806526184082, \"20077\": 0.41195443272590637, \"20100\": 0.8500841856002808, \"20116\": 0.21214580535888672, \"20155\": 0.9702757596969604, \"20177\": 0.24171993136405945, \"20253\": 0.10467668622732162, \"20274\": 0.11256109178066254, \"20367\": 0.45499902963638306, \"20662\": 0.7701805830001831, \"20794\": 0.6563454270362854, \"20806\": 0.08782484382390976, \"20962\": 0.8109301924705505, \"21150\": 0.1384023278951645, \"21262\": 0.1510767638683319, \"21371\": 0.6181373596191406, \"21374\": 0.9635916948318481, \"21961\": 0.07431721687316895, \"22261\": 0.0058422754518687725, \"22552\": 0.37304413318634033, \"22694\": 0.25239890813827515, \"22813\": 0.32341301441192627, \"22828\": 0.20022670924663544, \"22963\": 0.19541899859905243, \"23130\": 0.09228714555501938, \"23238\": 0.16110190749168396, \"23284\": 0.151916041970253, \"23435\": 1.1586239337921143, \"23614\": 0.28082266449928284, \"23655\": 0.040196798741817474, \"23676\": 0.20580662786960602, \"23737\": 0.052318159490823746, \"23807\": 0.011650617234408855, \"23900\": 0.14349138736724854, \"23915\": 0.014542185701429844, \"24081\": 0.21687394380569458, \"24098\": 0.08244366943836212, \"24110\": 0.6714286804199219, \"24209\": 0.1358480453491211, \"24269\": 0.026976587250828743, \"24327\": 0.08692999184131622, \"24558\": 0.06612417846918106, \"24624\": 0.24325250089168549, \"24844\": 0.012615402229130268, \"25137\": 1.0628231763839722, \"25172\": 0.4537591338157654, \"25604\": 0.6471850275993347, \"25610\": 0.7417513132095337, \"25870\": 0.05417001247406006, \"25972\": 0.45623743534088135, \"26014\": 0.6853039860725403, \"26287\": 0.1905880719423294, \"26290\": 0.11865071207284927, \"26396\": 0.24401791393756866, \"26563\": 0.8861536383628845, \"26743\": 0.09406650811433792, \"27011\": 1.2753846645355225, \"27162\": 0.14264501631259918, \"27166\": 0.32270604372024536, \"27312\": 0.11865071207284927, \"27404\": 0.5936289429664612, \"27453\": 0.21214580535888672, \"27480\": 0.10818854719400406, \"27532\": 0.4337083101272583, \"27815\": 0.3850763738155365, \"28086\": 0.30486753582954407, \"28105\": 0.6430866718292236, \"28228\": 0.8534175157546997, \"28329\": 0.055094651877880096, \"28397\": 0.026025565341114998, \"28436\": 0.16110190749168396, \"28828\": 0.12470348179340363, \"29101\": 0.09050461649894714, \"29150\": 0.026976587250828743, \"29366\": 0.5898461937904358, \"29458\": 0.10291612148284912}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(f\"nirantk/{dataset_name}-sparse-vectors\", split=\"train\")\n",
    "ds[source_col_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sparse_vectors = [json.loads(x) for x in ds[source_col_name]]\n",
    "tokenizer = Tokenizer.from_pretrained(source_model)\n",
    "reverse_voc = {v: k for k, v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vectors = []\n",
    "for sv in source_sparse_vectors:\n",
    "    raw_vectors.append(\n",
    "        {\n",
    "            \"tokens\": [reverse_voc[int(key)] for key in sv.keys()],\n",
    "            \"weights\": list(sv.values()),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombine and Retokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(raw_vectors.pop(2)[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4792ab2f32545aabc54897556a169b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retokenize_sparse_vector(text: str, source_sparse_vector: Dict[str, float], tokenizer: Tokenizer):\n",
    "    total_tokens_overall = 0\n",
    "    num_docs = 0\n",
    "    max_token_weight, num_tokens, total_tokens = {}, {}, 0\n",
    "\n",
    "    sequential_tokens = tokenizer.encode(text).tokens\n",
    "    reconstructed = reconstruct_bpe(enumerate(sequential_tokens))\n",
    "\n",
    "    # print(\"reconstructed:\\t\", reconstructed)\n",
    "\n",
    "    filtered_reconstructed = filter_pair_tokens(reconstructed)\n",
    "\n",
    "    # print(\"filtered:\\t\", filtered_reconstructed)\n",
    "\n",
    "    stemmed_reconstructed = stem_pair_tokens(filtered_reconstructed)\n",
    "\n",
    "    # print(\"stemmed:\\t\", stemmed_reconstructed)\n",
    "    # print(\"weights:\\t\", source_sparse_vector[\"weights\"])\n",
    "    weighed_reconstructed = aggregate_weights(\n",
    "        stemmed_reconstructed, source_sparse_vector[\"weights\"]\n",
    "    )\n",
    "\n",
    "    # print(\"weighted:\\t\", weighed_reconstructed)\n",
    "\n",
    "    total_tokens += len(weighed_reconstructed)\n",
    "    max_token_weight, num_tokens = {}, {}\n",
    "    for reconstructed_token, score in weighed_reconstructed:\n",
    "        max_token_weight[reconstructed_token] = max(\n",
    "            max_token_weight.get(reconstructed_token, 0), score\n",
    "        )\n",
    "        num_tokens[reconstructed_token] = num_tokens.get(reconstructed_token, 0) + 1\n",
    "\n",
    "    # print()\n",
    "    # tokens = stem_list_tokens(filter_list_tokens(snowball_tokenize(text)))\n",
    "    # total_tokens = len(tokens)\n",
    "    # num_tokens = Counter(tokens)\n",
    "    reweighted_sparse_vector = {}\n",
    "    token_score = rescore_vector(max_token_weight)\n",
    "    # print(\"token_score:\\t\", token_score)\n",
    "    for token, token_count in num_tokens.items():\n",
    "        score = token_score.get(token)\n",
    "        tf = score + token_count - 1\n",
    "        reweighted_sparse_vector[token] = calc_tf(tf, total_tokens)\n",
    "\n",
    "\n",
    "    total_tokens_overall += total_tokens\n",
    "    num_docs += 1\n",
    "    # print(len(reweighted_sparse_vector))\n",
    "    # print(\"reweighted_sparse_vector:\\t\", reweighted_sparse_vector)\n",
    "    if not len(reweighted_sparse_vector) <= 1.2 * len(source_sparse_vector[\"tokens\"]):\n",
    "        print(reweighted_sparse_vector)\n",
    "        print(source_sparse_vector)\n",
    "        print(len(reweighted_sparse_vector), len(source_sparse_vector[\"tokens\"]))\n",
    "        raise ValueError(\"Something went wrong\")\n",
    "    return reweighted_sparse_vector\n",
    "\n",
    "\n",
    "reweighted_sparse_vectors = []\n",
    "for source_sparse_vector, text in tqdm(\n",
    "    zip(raw_vectors, ds[\"text\"]), total=len(raw_vectors)\n",
    "):  \n",
    "    reweighted_sparse_vector = retokenize_sparse_vector(source_sparse_vector=source_sparse_vector, text=text, tokenizer=tokenizer)\n",
    "    # print(len(source_sparse_vectors))\n",
    "    reweighted_sparse_vectors.append(reweighted_sparse_vector)\n",
    "    # print(len(reweighted_sparse_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38., 45., 53.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find length of each sparse vector\n",
    "vector_lengths = [len(sv) for sv in reweighted_sparse_vectors]\n",
    "\n",
    "# Percentile of the lengths\n",
    "np.percentile(vector_lengths, [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(reweighted_sparse_vectors), reweighted_sparse_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QdrantClient' object has no attribute 'collectio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m QdrantClient(url\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQDRANT_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m), api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQDRANT_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectio\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_empty\u001b[39m(client: QdrantClient, collection_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mget_collection(collection_name)\u001b[38;5;241m.\u001b[39mpoints_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QdrantClient' object has no attribute 'collectio'"
     ]
    }
   ],
   "source": [
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))\n",
    "client.collectio\n",
    "\n",
    "def is_empty(client: QdrantClient, collection_name: str) -> bool:\n",
    "    return client.get_collection(collection_name).points_count == 0\n",
    "\n",
    "\n",
    "# client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_collection(client: QdrantClient, collection_name: str):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},\n",
    "        sparse_vectors_config={\n",
    "            col_name: models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams(on_disk=False)\n",
    "            )\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vocab of all keys in the reweighted sparse vectors\n",
    "vocab = set()\n",
    "for sv in reweighted_sparse_vectors:\n",
    "    vocab.update(sv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into a vocab object with each string having an id\n",
    "vocab = {word: i for i, word in enumerate(vocab)}\n",
    "invert_vocab = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute the reweighted sparse vectors with the new vocab\n",
    "id_reweighted_sparse_vectors = []\n",
    "for sv in tqdm(reweighted_sparse_vectors):\n",
    "    new_sv = {}\n",
    "    for word, weight in sv.items():\n",
    "        new_sv[vocab[word]] = weight\n",
    "    id_reweighted_sparse_vectors.append(new_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable: Iterable, n: int = 1) -> Iterable:\n",
    "    \"\"\"Yield successive n-sized chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_points(\n",
    "    reweighted_sparse_vectors: Dict, ds: Dataset\n",
    ") -> Iterable[models.PointStruct]:\n",
    "    points = []\n",
    "    for sv, element in tqdm(zip(reweighted_sparse_vectors, ds)):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(element[\"_id\"]),\n",
    "                vector={col_name: convert_sparse_vector(sv)},\n",
    "                payload={\n",
    "                    \"text\": element[\"text\"],\n",
    "                    \"title\": element[\"title\"],\n",
    "                    \"id\": element[\"_id\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return points\n",
    "\n",
    "\n",
    "# next(read_data(id_reweighted_sparse_vectors, ds))\n",
    "reset_collection(client, collection_name)\n",
    "points = make_points(id_reweighted_sparse_vectors, ds)\n",
    "# Run ONCE to upload data, only when collection is empty\n",
    "for batch in tqdm(batched(points, 100)):\n",
    "    try:\n",
    "        client.upload_points(collection_name=collection_name, points=batch)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"../data/{dataset_name}/qrels/test.tsv\", sep=\"\\t\")\n",
    "test[\"query-id\"] = test[\"query-id\"].astype(int)\n",
    "\n",
    "with open(f\"../data/{dataset_name}/queries.jsonl\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n",
    "\n",
    "# Only keep the test set queries\n",
    "queries = [q for q in queries if int(q[\"_id\"]) in list(test[\"query-id\"])]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"nirantk/splade-v3-lexical\")\n",
    "tokens = [tokenizer.encode(q[\"text\"]).tokens for q in queries]\n",
    "tokens = [list(set(t)) for t in tokens]\n",
    "# tokens = [list(set(t.ids)) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "tokens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign weight to all tokens and create a query vector with tokens and weights as keys\n",
    "query_vectors = []\n",
    "for token in tokens:\n",
    "    query_vector = {}\n",
    "    query_vector[\"tokens\"] = token\n",
    "    query_vector[\"weights\"] = [1] * len(token)\n",
    "    query_vectors.append(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retokenize all the query tokens\n",
    "reweighted_query_tokens = []\n",
    "for qv, text in tqdm(zip(query_vectors, [q[\"text\"] for q in queries])):\n",
    "    # print(text)\n",
    "    # print(qv)\n",
    "    reweighted_query_tokens.append(retokenize_sparse_vector(source_sparse_vector=qv, text=text, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reweighted_query_tokens[idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([len(t) for t in reweighted_query_tokens], [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the keys back to the original vocab with integer ids\n",
    "id_reweighted_query_tokens = []\n",
    "for qv in tqdm(reweighted_query_tokens):\n",
    "    new_qv = {}\n",
    "    for word, weight in qv.items():\n",
    "        try:\n",
    "            new_qv[vocab[word]] = weight    \n",
    "        except KeyError:\n",
    "            print(word)\n",
    "            continue\n",
    "    id_reweighted_query_tokens.append(new_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors = [\n",
    "    models.SparseVector(\n",
    "        indices=qv.keys(),\n",
    "        values=qv.values(),\n",
    "    )\n",
    "    for qv in id_reweighted_query_tokens\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10\n",
    "results = []\n",
    "for qv in tqdm(qdrant_query_vectors):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=models.NamedSparseVector(name=col_name, vector=qv),\n",
    "            with_payload=True,\n",
    "            limit=limit,\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(qv)\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids, doc_ids, ranks, scores  = [], [], [], []\n",
    "for query, result in zip(queries, results):\n",
    "    query_id = query[\"_id\"]\n",
    "    result_ids = [str(r.id) for r in result]\n",
    "    result_scores = [r.score for r in result]\n",
    "    result_ranks = list(range(len(result)))\n",
    "    query_ids.extend(len(result) * [query_id])\n",
    "    doc_ids.extend(result_ids)\n",
    "    ranks.extend(result_ranks)\n",
    "    scores.extend(result_scores)\n",
    "    # print(f\"query: {query_id}\")\n",
    "    # print(f\"docid: {result_ids}\")\n",
    "    # print(f\"rank: {result_ranks}\")\n",
    "    # print(f\"score: {result_scores}\")\n",
    "\n",
    "run = {\n",
    "    \"query\": [int(q) for q in query_ids],\n",
    "    \"q0\": len(query_ids) * [\"q0\"],\n",
    "    \"docid\": doc_ids,\n",
    "    \"rank\": ranks,\n",
    "    \"score\": scores,\n",
    "    \"system\": len(query_ids) * [\"splade\"],\n",
    "}\n",
    "\n",
    "with open(\"lexical-retokenize-rescore.run.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightsplade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
