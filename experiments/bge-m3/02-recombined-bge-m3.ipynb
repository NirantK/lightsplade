{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "from remap_tokens import (\n",
    "    aggregate_weights,\n",
    "    calc_tf,\n",
    "    filter_pair_tokens,\n",
    "    reconstruct_sentence_piece,\n",
    "    reconstruct_bpe,\n",
    "    rescore_vector,\n",
    "    stem_pair_tokens,\n",
    ")\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def convert_sparse_vector(sparse_vector: Dict) -> models.SparseVector:\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for idx, value in sparse_vector.items():\n",
    "        indices.append(int(idx))\n",
    "        values.append(value)\n",
    "\n",
    "    return models.SparseVector(indices=indices, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# experiment parameters\n",
    "canonical_dataset_name = \"scifact\"\n",
    "dataset_name = \"scifact-bge-m3-sparse-vectors\"\n",
    "source_col_name = col_name = \"bge_m3_sparse_vector\"\n",
    "collection_name = f\"{dataset_name}-{col_name}-retok\"\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "LOG_RESCORING: bool = False\n",
    "RECONSTRUCT: object = reconstruct_bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"39176\": 0.1639404296875, \"21094\": 0.033599853515625, \"159958\": 0.1788330078125, \"119856\": 0.1939697265625, \"35011\": 0.1964111328125, \"26866\": 0.2216796875, \"70\": 0.011077880859375, \"168698\": 0.161865234375, \"14135\": 0.04254150390625, \"78574\": 0.1883544921875, \"831\": 0.051239013671875, \"52490\": 0.16845703125, \"8231\": 0.067626953125, \"70760\": 0.1358642578125, \"34754\": 0.1903076171875, \"136\": 0.01042938232421875, \"16750\": 0.024810791015625, \"23\": 0.01120758056640625, \"123309\": 0.1346435546875, \"164462\": 0.1981201171875, \"13315\": 0.131591796875, \"44954\": 0.168701171875, \"45755\": 0.1553955078125, \"92105\": 0.1864013671875, \"9\": 0.01116943359375, \"165598\": 0.1431884765625, \"297\": 0.010650634765625, \"214706\": 0.0733642578125, \"3332\": 0.016510009765625, \"191\": 0.01358795166015625, \"7154\": 0.00965118408203125, \"86898\": 0.06939697265625, \"177\": 0.0108184814453125, \"594\": 0.03509521484375, \"16625\": 0.197265625, \"16\": 0.0110626220703125, \"944\": 0.052734375, \"3956\": 0.0084228515625, \"1492\": 0.15283203125, \"4970\": 0.1644287109375, \"114137\": 0.157470703125, \"190659\": 0.030487060546875, \"72350\": 0.1312255859375, \"173676\": 0.300537109375, \"552\": 0.07379150390625, \"13\": 0.0109710693359375, \"24500\": 0.1395263671875, \"45964\": 0.0036983489990234375, \"4\": 0.011260986328125, \"74481\": 0.09429931640625, \"67\": 0.01102447509765625, \"35845\": 0.18408203125, \"1866\": 0.1240234375, \"991\": 0.059906005859375, \"29813\": 0.2294921875, \"53\": 0.01084136962890625, \"2256\": 0.07647705078125, \"2182\": 0.01110076904296875, \"17262\": 0.07257080078125, \"157955\": 0.11798095703125, \"109197\": 0.191162109375, \"479\": 0.11041259765625, \"32166\": 0.22314453125, \"15\": 0.0109710693359375, \"19\": 0.007411956787109375, \"2203\": 0.01097869873046875, \"729\": 0.07940673828125, \"4393\": 0.0728759765625, \"145048\": 0.2222900390625, \"49413\": 0.0479736328125, \"202120\": 0.0888671875, \"93425\": 0.1439208984375, \"111\": 0.0111846923828125, \"170176\": 0.2430419921875, \"2481\": 0.1390380859375, \"39395\": 0.0487060546875, \"700\": 0.08599853515625, \"41311\": 0.12744140625, \"209\": 0.048736572265625, \"3542\": 0.0108795166015625, \"22282\": 0.06719970703125, \"71\": 0.01125335693359375, \"10\": 0.01105499267578125, \"17932\": 0.0885009765625, \"1733\": 0.047821044921875, \"99\": 0.0111083984375, \"13579\": 0.1953125, \"9879\": 0.1702880859375, \"29459\": 0.1761474609375, \"1372\": 0.1883544921875, \"148\": 0.0596923828125, \"92\": 0.06829833984375, \"509\": 0.0100555419921875, \"11192\": 0.061279296875, \"79875\": 0.08502197265625, \"11948\": 0.08941650390625, \"39\": 0.01090240478515625, \"45792\": 0.00933074951171875, \"4432\": 0.08441162109375, \"227204\": 0.17333984375, \"154732\": 0.0090789794921875, \"47\": 0.0106964111328125, \"39225\": 0.162353515625, \"400\": 0.062408447265625, \"6492\": 0.047821044921875, \"70796\": 0.1552734375, \"150143\": 0.1650390625, \"4240\": 0.07659912109375, \"11044\": 0.072509765625, \"35066\": 0.0104217529296875, \"15044\": 0.01047515869140625, \"20028\": 0.01029205322265625, \"21373\": 0.086181640625, \"119475\": 0.008392333984375, \"231839\": 0.13818359375, \"77546\": 0.146728515625, \"20903\": 0.12060546875, \"42\": 0.01117706298828125, \"127319\": 0.1744384765625, \"678\": 0.0109405517578125, \"117396\": 0.025146484375, \"89931\": 0.130859375, \"3501\": 0.008514404296875, \"1914\": 0.12408447265625, \"91977\": 0.0919189453125, \"617\": 0.01123046875, \"615\": 0.010650634765625, \"1837\": 0.01062774658203125, \"194692\": 0.01126861572265625, \"89678\": 0.0265045166015625, \"1126\": 0.01122283935546875, \"915\": 0.0110321044921875, \"60978\": 0.01024627685546875, \"92319\": 0.12261962890625, \"58555\": 0.009979248046875, \"154186\": 0.0019407272338867188, \"148477\": 0.0716552734375, \"6\": 0.0110626220703125, \"122887\": 0.002315521240234375, \"8892\": 0.01103973388671875, \"17596\": 0.0077362060546875, \"29094\": 0.01113128662109375, \"6746\": 0.01122283935546875, \"74\": 0.01128387451171875, \"151152\": 0.0341796875, \"1398\": 0.01102447509765625, \"12465\": 0.01122283935546875, \"97109\": 0.01113128662109375, \"757\": 0.01102447509765625, \"5\": 0.01108551025390625, \"110156\": 0.01325225830078125, \"3775\": 0.045745849609375, \"1176\": 0.007965087890625, \"37755\": 0.1085205078125, \"27686\": 0.01065826416015625, \"7\": 0.01117706298828125, \"88591\": 0.1160888671875, \"11782\": 0.10772705078125, \"232\": 0.0697021484375, \"316\": 0.042694091796875, \"75693\": 0.11834716796875, \"390\": 0.01073455810546875, \"237\": 0.011077880859375, \"168360\": 0.00615692138671875, \"60212\": 0.146240234375, \"53702\": 0.1529541015625, \"581\": 0.010986328125, \"450\": 0.0112152099609375, \"88779\": 0.046142578125, \"5844\": 0.01117706298828125, \"164031\": 0.09832763671875, \"7401\": 0.145751953125, \"276\": 0.016021728515625, \"149201\": 0.08697509765625, \"3934\": 0.0067291259765625, \"36716\": 0.07403564453125, \"82451\": 0.005756378173828125, \"38043\": 0.1378173828125}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(f\"nirantk/{dataset_name}\", split=\"corpus\")\n",
    "ds[col_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = [json.loads(x) for x in ds[source_col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "vocab = tokenizer.get_vocab()\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombine and Retokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vectors = []\n",
    "for sv in sparse_vectors:\n",
    "    raw_vectors.append(\n",
    "        {\n",
    "            \"tokens\": [reverse_vocab[int(key)] for key in sv.keys()],\n",
    "            \"weights\": list(sv.values()),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b773ab8e9497eaaa160c4bde8d1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retokenize_sparse_vector(\n",
    "    text: str,\n",
    "    source_sparse_vector: Dict[str, float],\n",
    "    tokenizer: Tokenizer,\n",
    "    rescore: bool,\n",
    "):\n",
    "    total_tokens_overall = 0\n",
    "    num_docs = 0\n",
    "    max_token_weight, num_tokens, total_tokens = {}, {}, 0\n",
    "\n",
    "    sequential_tokens = tokenizer.tokenize(text)\n",
    "    reconstructed = RECONSTRUCT(sequential_tokens)\n",
    "\n",
    "    # print(\"reconstructed:\\t\", reconstructed)\n",
    "\n",
    "    filtered_reconstructed = filter_pair_tokens(reconstructed)\n",
    "\n",
    "    # print(\"filtered:\\t\", filtered_reconstructed)\n",
    "\n",
    "    stemmed_reconstructed = stem_pair_tokens(filtered_reconstructed)\n",
    "\n",
    "    # print(\"stemmed:\\t\", stemmed_reconstructed)\n",
    "    # print(\"weights:\\t\", source_sparse_vector[\"weights\"])\n",
    "    weighed_reconstructed = aggregate_weights(\n",
    "        stemmed_reconstructed, source_sparse_vector[\"weights\"]\n",
    "    )\n",
    "\n",
    "    # print(\"weighted:\\t\", weighed_reconstructed)\n",
    "    if not rescore:\n",
    "        return dict(weighed_reconstructed)\n",
    "    # print(f\"LOG_RESCORING is set to {LOG_RESCORING}\")\n",
    "    total_tokens += len(weighed_reconstructed)\n",
    "    max_token_weight, num_tokens = {}, {}\n",
    "    for reconstructed_token, score in weighed_reconstructed:\n",
    "        max_token_weight[reconstructed_token] = max(\n",
    "            max_token_weight.get(reconstructed_token, 0), score\n",
    "        )\n",
    "        num_tokens[reconstructed_token] = num_tokens.get(reconstructed_token, 0) + 1\n",
    "    reweighted_sparse_vector = {}\n",
    "    token_score = rescore_vector(max_token_weight)\n",
    "    # print(\"token_score:\\t\", token_score)\n",
    "    for token, token_count in num_tokens.items():\n",
    "        score = token_score.get(token)\n",
    "        tf = score + token_count - 1\n",
    "        reweighted_sparse_vector[token] = calc_tf(tf, total_tokens)\n",
    "\n",
    "    total_tokens_overall += total_tokens\n",
    "    num_docs += 1\n",
    "    # print(len(reweighted_sparse_vector))\n",
    "    # print(\"reweighted_sparse_vector:\\t\", reweighted_sparse_vector)\n",
    "    # if not len(reweighted_sparse_vector) <= 1.2 * len(source_sparse_vector[\"tokens\"]):\n",
    "    #     print(reweighted_sparse_vector)\n",
    "    #     print(source_sparse_vector)\n",
    "    #     print(len(reweighted_sparse_vector), len(source_sparse_vector[\"tokens\"]))\n",
    "    #     raise ValueError(\"Something went wrong\")\n",
    "    return reweighted_sparse_vector\n",
    "\n",
    "\n",
    "reweighted_sparse_vectors = []\n",
    "for source_sparse_vector, text in tqdm(\n",
    "    zip(raw_vectors, ds[\"text\"]), total=len(raw_vectors)\n",
    "):\n",
    "    reweighted_sparse_vector = retokenize_sparse_vector(\n",
    "        source_sparse_vector=source_sparse_vector,\n",
    "        text=text,\n",
    "        tokenizer=tokenizer,\n",
    "        rescore=LOG_RESCORING,\n",
    "    )\n",
    "    # print(len(source_sparse_vectors))\n",
    "    reweighted_sparse_vectors.append(reweighted_sparse_vector)\n",
    "    # print(len(reweighted_sparse_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁alter': 0.1639404296875,\n",
       " 'ation': 0.033599853515625,\n",
       " '▁of': 0.0,\n",
       " '▁the': 0.0,\n",
       " '▁': 0.0,\n",
       " 'architectur': 0.1953125,\n",
       " '▁cerebr': 0.0,\n",
       " '▁white': 0.0,\n",
       " '▁matter': 0.0,\n",
       " '▁in': 0.0,\n",
       " '▁develop': 0.0,\n",
       " '▁human': 0.1358642578125,\n",
       " '▁brain': 0.1903076171875,\n",
       " '▁can': 0.01042938232421875,\n",
       " '▁affect': 0.024810791015625,\n",
       " '▁cor': 0.01120758056640625,\n",
       " 'tical': 0.1346435546875,\n",
       " '▁and': 0.0,\n",
       " '▁result': 0.168701171875,\n",
       " '▁function': 0.1864013671875,\n",
       " '▁disabili': 0.01116943359375,\n",
       " 'tie': 0.1431884765625,\n",
       " '▁a': 0.0019407272338867188,\n",
       " '▁line': 0.016510009765625,\n",
       " '▁scan': 0.01358795166015625,\n",
       " '▁dif': 0.0,\n",
       " 'fusion': 0.0,\n",
       " 'weight': 0.03509521484375,\n",
       " 'ed': 0.197265625,\n",
       " '▁magnet': 0.0110626220703125,\n",
       " '▁res': 0.052734375,\n",
       " 'anc': 0.15283203125,\n",
       " '▁imagin': 0.1644287109375,\n",
       " 'g': 0.157470703125,\n",
       " '▁(': 0.0,\n",
       " 'm': 0.1312255859375,\n",
       " 'ri': 0.0,\n",
       " '▁se': 0.0109710693359375,\n",
       " 'que': 0.1395263671875,\n",
       " 'nce': 0.0036983489990234375,\n",
       " '▁with': 0.0,\n",
       " '▁ten': 0.0,\n",
       " 'sor': 0.0,\n",
       " '▁analysi': 0.059906005859375,\n",
       " '▁was': 0.0,\n",
       " '▁appli': 0.01084136962890625,\n",
       " '▁to': 0.0,\n",
       " '▁measur': 0.01110076904296875,\n",
       " '▁appar': 0.0,\n",
       " '▁co': 0.0,\n",
       " 'e': 0.0,\n",
       " 'ffi': 0.1085205078125,\n",
       " 'cient': 0.01065826416015625,\n",
       " '▁calcula': 0.2222900390625,\n",
       " 'te': 0.0479736328125,\n",
       " '▁relat': 0.0,\n",
       " '▁ani': 0.0,\n",
       " 'trop': 0.0,\n",
       " '▁de': 0.048736572265625,\n",
       " 'line': 0.0108795166015625,\n",
       " 'ate': 0.0,\n",
       " '▁three': 0.01125335693359375,\n",
       " 'dimension': 0.0885009765625,\n",
       " '▁fiber': 0.0,\n",
       " '▁pre': 0.0,\n",
       " 'term': 0.0,\n",
       " 'n': 0.01126861572265625,\n",
       " '▁=': 0.0,\n",
       " '▁17': 0.00933074951171875,\n",
       " '▁full': 0.0,\n",
       " '▁infant': 0.0,\n",
       " '▁7)': 0.07659912109375,\n",
       " '▁assess': 0.0,\n",
       " '▁effect': 0.01029205322265625,\n",
       " '▁prematur': 0.008392333984375,\n",
       " 'iti': 0.13818359375,\n",
       " '▁on': 0.146728515625,\n",
       " '▁ear': 0.0,\n",
       " '▁ge': 0.008514404296875,\n",
       " 'station': 0.12408447265625,\n",
       " '▁10': 0.01122283935546875,\n",
       " '▁were': 0.0,\n",
       " '▁studi': 0.12261962890625,\n",
       " '▁second': 0.0716552734375,\n",
       " '▁time': 0.0,\n",
       " '▁at': 0.0,\n",
       " '▁term': 0.0,\n",
       " '▁central': 0.0,\n",
       " '▁mean': 0.0,\n",
       " '▁28': 0.0,\n",
       " '▁w': 0.0,\n",
       " 'k': 0.0,\n",
       " '▁high': 0.11834716796875,\n",
       " '▁1.8': 0.011077880859375,\n",
       " '▁micro': 0.0,\n",
       " '2/': 0.0,\n",
       " 'ms': 0.0,\n",
       " '▁decreas': 0.01117706298828125,\n",
       " '▁toward': 0.145751953125,\n",
       " '▁1.2': 0.0067291259765625,\n",
       " '▁posterior': 0.0,\n",
       " '▁li': 0.0,\n",
       " 'mb': 0.0,\n",
       " '▁intern': 0.0,\n",
       " '▁capsul': 0.0,\n",
       " 'ef': 0.0,\n",
       " 'fici': 0.0,\n",
       " 'ent': 0.0,\n",
       " '▁both': 0.0,\n",
       " '▁similar': 0.0,\n",
       " '1.2': 0.0,\n",
       " '▁versus': 0.0,\n",
       " '▁1.1': 0.0,\n",
       " ').': 0.0,\n",
       " '▁relativ': 0.0,\n",
       " '▁higher': 0.0,\n",
       " '▁close': 0.0,\n",
       " 'r': 0.0,\n",
       " '▁birth': 0.0,\n",
       " '▁greater': 0.0,\n",
       " '▁absolut': 0.0,\n",
       " '▁valu': 0.0,\n",
       " '▁than': 0.0,\n",
       " '▁show': 0.0,\n",
       " '1.4': 0.0,\n",
       " '▁+/-': 0.0,\n",
       " '▁0.2': 0.0,\n",
       " '4': 0.0,\n",
       " '▁1.': 0.0,\n",
       " '15': 0.0,\n",
       " '▁0.0': 0.0,\n",
       " '9': 0.0,\n",
       " '▁p': 0.0,\n",
       " '16)': 0.0,\n",
       " '▁lower': 0.0,\n",
       " '▁area': 0.0,\n",
       " '▁compar': 0.0,\n",
       " 'white': 0.0,\n",
       " '▁10.': 0.0,\n",
       " '0.6': 0.0,\n",
       " '▁22.': 0.0,\n",
       " '▁3.0': 0.0,\n",
       " '%,': 0.0,\n",
       " '01': 0.0,\n",
       " '▁2': 0.0,\n",
       " '4.0': 0.0,\n",
       " '▁4.': 0.0,\n",
       " '44': 0.0,\n",
       " '▁3': 0.0,\n",
       " '3.1': 0.0,\n",
       " '▁0': 0.0,\n",
       " '6%': 0.0,\n",
       " '06)': 0.0,\n",
       " '▁non': 0.0,\n",
       " 'elin': 0.0,\n",
       " '▁corpus': 0.0,\n",
       " '▁call': 0.0,\n",
       " 'os': 0.0,\n",
       " 'um': 0.0,\n",
       " '▁visibl': 0.0,\n",
       " '▁bi': 0.0,\n",
       " '▁m': 0.0,\n",
       " '▁as': 0.0,\n",
       " '▁mark': 0.0,\n",
       " '▁differ': 0.0,\n",
       " '▁organ': 0.0,\n",
       " '▁data': 0.0,\n",
       " '▁indic': 0.0,\n",
       " '▁that': 0.0,\n",
       " '▁quantitat': 0.0,\n",
       " 'ive': 0.0,\n",
       " '▁water': 0.0,\n",
       " '▁provid': 0.0,\n",
       " '▁insight': 0.0,\n",
       " '▁into': 0.0,\n",
       " 'struct': 0.0,\n",
       " 'ural': 0.0,\n",
       " '▁live': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reweighted_sparse_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105., 156., 219.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find length of each sparse vector\n",
    "vector_lengths = [len(sv) for sv in reweighted_sparse_vectors]\n",
    "\n",
    "# Percentile of the lengths\n",
    "np.percentile(vector_lengths, [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(reweighted_sparse_vectors), reweighted_sparse_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))\n",
    "\n",
    "\n",
    "def is_empty(client: QdrantClient, collection_name: str) -> bool:\n",
    "    return client.get_collection(collection_name).points_count == 0\n",
    "\n",
    "\n",
    "# client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_collection(client: QdrantClient, collection_name: str):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},\n",
    "        sparse_vectors_config={\n",
    "            col_name: models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams(on_disk=False)\n",
    "            )\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vocab of all keys in the reweighted sparse vectors\n",
    "vocab = set()\n",
    "for sv in reweighted_sparse_vectors:\n",
    "    vocab.update(sv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12925"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into a vocab object with each string having an id\n",
    "vocab = {word: i for i, word in enumerate(vocab)}\n",
    "invert_vocab = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36b8d41c37d487fa5f2d762038f52df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recompute the reweighted sparse vectors with the new vocab\n",
    "id_reweighted_sparse_vectors = []\n",
    "for sv in tqdm(reweighted_sparse_vectors):\n",
    "    new_sv = {}\n",
    "    for word, weight in sv.items():\n",
    "        new_sv[vocab[word]] = weight\n",
    "    id_reweighted_sparse_vectors.append(new_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable: Iterable, n: int = 1) -> Iterable:\n",
    "    \"\"\"Yield successive n-sized chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9171cf3ba46b48bea3292007c998c45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7793f052db384e729991f47a0912650c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_points(\n",
    "    reweighted_sparse_vectors: Dict, ds: Dataset\n",
    ") -> Iterable[models.PointStruct]:\n",
    "    points = []\n",
    "    for sv, element in tqdm(zip(reweighted_sparse_vectors, ds)):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(element[\"_id\"]),\n",
    "                vector={col_name: convert_sparse_vector(sv)},\n",
    "                payload={\n",
    "                    \"text\": element[\"text\"],\n",
    "                    \"title\": element[\"title\"],\n",
    "                    \"id\": element[\"_id\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return points\n",
    "\n",
    "\n",
    "# next(read_data(id_reweighted_sparse_vectors, ds))\n",
    "reset_collection(client, collection_name)\n",
    "points = make_points(id_reweighted_sparse_vectors, ds)\n",
    "# Run ONCE to upload data, only when collection is empty\n",
    "for batch in tqdm(batched(points, 1000)):\n",
    "    try:\n",
    "        client.upload_points(collection_name=collection_name, points=batch)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f\"../../data/{canonical_dataset_name}/qrels/test.tsv\", sep=\"\\t\")\n",
    "test[\"query-id\"] = test[\"query-id\"].astype(int)\n",
    "\n",
    "with open(f\"../../data/{canonical_dataset_name}/queries.jsonl\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n",
    "\n",
    "# Only keep the test set queries\n",
    "queries = [q for q in queries if int(q[\"_id\"]) in list(test[\"query-id\"])]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c144eb0400644bdf9cc0538748ca49f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BGEM3FlagModel(\n",
    "    \"BAAI/bge-m3\", use_fp16=True\n",
    ")  # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "\n",
    "def get_sparse_vector(batch: List[str]):\n",
    "    output = model.encode(\n",
    "        batch, return_dense=False, return_sparse=True, return_colbert_vecs=False\n",
    "    )\n",
    "    return output[\"lexical_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 25/25 [00:02<00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 s, sys: 272 ms, total: 1.82 s\n",
      "Wall time: 2.46 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_query_vectors = get_sparse_vector([q[\"text\"] for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'3980': 0.1531,\n",
       "             '25388': 0.1818,\n",
       "             '7': 0.03915,\n",
       "             '57913': 0.147,\n",
       "             '34080': 0.0839,\n",
       "             '3038': 0.06354,\n",
       "             '112': 0.002756,\n",
       "             '8': 0.09863,\n",
       "             '180220': 0.1117,\n",
       "             '1409': 0.04636,\n",
       "             '11044': 0.131,\n",
       "             '199334': 0.2042,\n",
       "             '23417': 0.2339,\n",
       "             '40715': 0.2086,\n",
       "             '450': 0.03105,\n",
       "             '351': 0.0846,\n",
       "             '3284': 0.1382,\n",
       "             '10484': 0.08466})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 50\n",
    "raw_query_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_float_query_vectors(\n",
    "    raw_query_vectors: List[Dict[str, float]],\n",
    ") -> List[Dict[str, List[float]]]:\n",
    "    float_query_vectors = []\n",
    "    for sv in raw_query_vectors:\n",
    "        new_sv = {}\n",
    "        new_sv[\"tokens\"] = list(sv.keys())\n",
    "        new_sv[\"weights\"] = [float(v) for v in sv.values()]\n",
    "        float_query_vectors.append(new_sv)\n",
    "    return float_query_vectors\n",
    "\n",
    "\n",
    "float_query_vectors = make_float_query_vectors(raw_query_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7d310a66e7467a99085d67b389aa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reweighted_query_vectors = []\n",
    "for source_query_vector, text in tqdm(\n",
    "    zip(float_query_vectors, [q[\"text\"] for q in queries])\n",
    "):\n",
    "    reweighted_qv = retokenize_sparse_vector(\n",
    "        source_sparse_vector=source_query_vector,\n",
    "        text=text,\n",
    "        tokenizer=tokenizer,\n",
    "        rescore=LOG_RESCORING,\n",
    "    )\n",
    "    reweighted_query_vectors.append(reweighted_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 18., 30.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(t) for t in reweighted_query_vectors], [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁0': 0.2288818359375,\n",
       " 'dimension': 0.2142333984375,\n",
       " '▁bio': 0.17333984375,\n",
       " 'materi': 0.271728515625,\n",
       " '▁show': 0.169677734375,\n",
       " '▁induc': 0.264404296875,\n",
       " 'tive': 0.1953125,\n",
       " '▁properti': 0.209716796875}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reweighted_query_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aad9922eb4847f0a8b917926ffb0577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/2000\n",
      "ordin\n",
      "▁alb\n",
      "▁galli\n",
      "▁gab\n",
      "mmel\n",
      "uer\n",
      "▁adept\n",
      "▁pola\n",
      "▁mata\n",
      "stes\n",
      "▁tira\n",
      "tiv\n",
      "▁casu\n"
     ]
    }
   ],
   "source": [
    "# Map the keys back to the original vocab with integer ids\n",
    "id_reweighted_query_tokens = []\n",
    "for qv in tqdm(reweighted_query_vectors):\n",
    "    new_qv = {}\n",
    "    for word, weight in qv.items():\n",
    "        try:\n",
    "            new_qv[vocab[word]] = weight\n",
    "        except KeyError:\n",
    "            print(word)\n",
    "            continue\n",
    "    id_reweighted_query_tokens.append(new_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors = [\n",
    "    models.SparseVector(\n",
    "        indices=qv.keys(),\n",
    "        values=qv.values(),\n",
    "    )\n",
    "    for qv in id_reweighted_query_tokens\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(indices=[8203, 9858, 12715, 2080, 5067, 10755, 736, 10938, 11613, 2337, 7857, 7167, 8379, 11517, 5722, 1169, 10309, 9423, 2726, 10375, 4310, 2399], values=[0.153076171875, 0.1817626953125, 0.14697265625, 0.08392333984375, 0.06353759765625, 0.0027561187744140625, 0.0986328125, 0.1116943359375, 0.2086181640625, 0.1309814453125, 0.2042236328125, 0.23388671875, 0.0310516357421875, 0.0845947265625, 0.13818359375, 0.08465576171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_query_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cc5aa5e9c74fd6a8f2804c32190c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit = 10\n",
    "results = []\n",
    "for qv in tqdm(qdrant_query_vectors):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=models.NamedSparseVector(name=col_name, vector=qv),\n",
    "            with_payload=True,\n",
    "            limit=limit,\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(qv)\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids, doc_ids, ranks, scores = [], [], [], []\n",
    "for query, result in zip(queries, results):\n",
    "    query_id = query[\"_id\"]\n",
    "    result_ids = [str(r.id) for r in result]\n",
    "    result_scores = [r.score for r in result]\n",
    "    result_ranks = list(range(len(result)))\n",
    "    query_ids.extend(len(result) * [query_id])\n",
    "    doc_ids.extend(result_ids)\n",
    "    ranks.extend(result_ranks)\n",
    "    scores.extend(result_scores)\n",
    "    # print(f\"query: {query_id}\")\n",
    "    # print(f\"docid: {result_ids}\")\n",
    "    # print(f\"rank: {result_ranks}\")\n",
    "    # print(f\"score: {result_scores}\")\n",
    "\n",
    "run = {\n",
    "    \"query\": [int(q) for q in query_ids],\n",
    "    \"q0\": len(query_ids) * [\"q0\"],\n",
    "    \"docid\": doc_ids,\n",
    "    \"rank\": ranks,\n",
    "    \"score\": scores,\n",
    "    \"system\": len(query_ids) * [\"bge-m3\"],\n",
    "}\n",
    "\n",
    "with open(f\"bge_m3_retoken_{RECONSTRUCT.__name__}_rescore_{LOG_RESCORING}.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightsplade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
