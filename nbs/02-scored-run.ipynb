{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from transformers import AutoTokenizer\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_sparse_tools import convert_sparse_vector\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FORCE_DELETE = False\n",
    "canonical_dataset_name = \"scifact\"\n",
    "dataset_name = \"scifact-bge-m3-sparse-vectors\"\n",
    "col_name = \"bge_m3_sparse_vector\"\n",
    "collection_name = f\"{dataset_name}-{col_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(client: QdrantClient, collection_name: str) -> bool:\n",
    "    return client.get_collection(collection_name).points_count == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if FORCE_DELETE:\n",
    "    client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = load_dataset(f\"nirantk/{dataset_name}\", split=\"corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'title', 'text', 'bge_m3_sparse_vector'],\n",
       "    num_rows: 5183\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_raw.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85e40bb8a3f4108a67e03038b9918d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'39176': 0.1639404296875,\n",
       " '21094': 0.033599853515625,\n",
       " '159958': 0.1788330078125,\n",
       " '119856': 0.1939697265625,\n",
       " '35011': 0.1964111328125,\n",
       " '26866': 0.2216796875,\n",
       " '70': 0.011077880859375,\n",
       " '168698': 0.161865234375,\n",
       " '14135': 0.04254150390625,\n",
       " '78574': 0.1883544921875,\n",
       " '831': 0.051239013671875,\n",
       " '52490': 0.16845703125,\n",
       " '8231': 0.067626953125,\n",
       " '70760': 0.1358642578125,\n",
       " '34754': 0.1903076171875,\n",
       " '136': 0.01042938232421875,\n",
       " '16750': 0.024810791015625,\n",
       " '23': 0.01120758056640625,\n",
       " '123309': 0.1346435546875,\n",
       " '164462': 0.1981201171875,\n",
       " '13315': 0.131591796875,\n",
       " '44954': 0.168701171875,\n",
       " '45755': 0.1553955078125,\n",
       " '92105': 0.1864013671875,\n",
       " '9': 0.01116943359375,\n",
       " '165598': 0.1431884765625,\n",
       " '297': 0.010650634765625,\n",
       " '214706': 0.0733642578125,\n",
       " '3332': 0.016510009765625,\n",
       " '191': 0.01358795166015625,\n",
       " '7154': 0.00965118408203125,\n",
       " '86898': 0.06939697265625,\n",
       " '177': 0.0108184814453125,\n",
       " '594': 0.03509521484375,\n",
       " '16625': 0.197265625,\n",
       " '16': 0.0110626220703125,\n",
       " '944': 0.052734375,\n",
       " '3956': 0.0084228515625,\n",
       " '1492': 0.15283203125,\n",
       " '4970': 0.1644287109375,\n",
       " '114137': 0.157470703125,\n",
       " '190659': 0.030487060546875,\n",
       " '72350': 0.1312255859375,\n",
       " '173676': 0.300537109375,\n",
       " '552': 0.07379150390625,\n",
       " '13': 0.0109710693359375,\n",
       " '24500': 0.1395263671875,\n",
       " '45964': 0.0036983489990234375,\n",
       " '4': 0.011260986328125,\n",
       " '74481': 0.09429931640625,\n",
       " '67': 0.01102447509765625,\n",
       " '35845': 0.18408203125,\n",
       " '1866': 0.1240234375,\n",
       " '991': 0.059906005859375,\n",
       " '29813': 0.2294921875,\n",
       " '53': 0.01084136962890625,\n",
       " '2256': 0.07647705078125,\n",
       " '2182': 0.01110076904296875,\n",
       " '17262': 0.07257080078125,\n",
       " '157955': 0.11798095703125,\n",
       " '109197': 0.191162109375,\n",
       " '479': 0.11041259765625,\n",
       " '32166': 0.22314453125,\n",
       " '15': 0.0109710693359375,\n",
       " '19': 0.007411956787109375,\n",
       " '2203': 0.01097869873046875,\n",
       " '729': 0.07940673828125,\n",
       " '4393': 0.0728759765625,\n",
       " '145048': 0.2222900390625,\n",
       " '49413': 0.0479736328125,\n",
       " '202120': 0.0888671875,\n",
       " '93425': 0.1439208984375,\n",
       " '111': 0.0111846923828125,\n",
       " '170176': 0.2430419921875,\n",
       " '2481': 0.1390380859375,\n",
       " '39395': 0.0487060546875,\n",
       " '700': 0.08599853515625,\n",
       " '41311': 0.12744140625,\n",
       " '209': 0.048736572265625,\n",
       " '3542': 0.0108795166015625,\n",
       " '22282': 0.06719970703125,\n",
       " '71': 0.01125335693359375,\n",
       " '10': 0.01105499267578125,\n",
       " '17932': 0.0885009765625,\n",
       " '1733': 0.047821044921875,\n",
       " '99': 0.0111083984375,\n",
       " '13579': 0.1953125,\n",
       " '9879': 0.1702880859375,\n",
       " '29459': 0.1761474609375,\n",
       " '1372': 0.1883544921875,\n",
       " '148': 0.0596923828125,\n",
       " '92': 0.06829833984375,\n",
       " '509': 0.0100555419921875,\n",
       " '11192': 0.061279296875,\n",
       " '79875': 0.08502197265625,\n",
       " '11948': 0.08941650390625,\n",
       " '39': 0.01090240478515625,\n",
       " '45792': 0.00933074951171875,\n",
       " '4432': 0.08441162109375,\n",
       " '227204': 0.17333984375,\n",
       " '154732': 0.0090789794921875,\n",
       " '47': 0.0106964111328125,\n",
       " '39225': 0.162353515625,\n",
       " '400': 0.062408447265625,\n",
       " '6492': 0.047821044921875,\n",
       " '70796': 0.1552734375,\n",
       " '150143': 0.1650390625,\n",
       " '4240': 0.07659912109375,\n",
       " '11044': 0.072509765625,\n",
       " '35066': 0.0104217529296875,\n",
       " '15044': 0.01047515869140625,\n",
       " '20028': 0.01029205322265625,\n",
       " '21373': 0.086181640625,\n",
       " '119475': 0.008392333984375,\n",
       " '231839': 0.13818359375,\n",
       " '77546': 0.146728515625,\n",
       " '20903': 0.12060546875,\n",
       " '42': 0.01117706298828125,\n",
       " '127319': 0.1744384765625,\n",
       " '678': 0.0109405517578125,\n",
       " '117396': 0.025146484375,\n",
       " '89931': 0.130859375,\n",
       " '3501': 0.008514404296875,\n",
       " '1914': 0.12408447265625,\n",
       " '91977': 0.0919189453125,\n",
       " '617': 0.01123046875,\n",
       " '615': 0.010650634765625,\n",
       " '1837': 0.01062774658203125,\n",
       " '194692': 0.01126861572265625,\n",
       " '89678': 0.0265045166015625,\n",
       " '1126': 0.01122283935546875,\n",
       " '915': 0.0110321044921875,\n",
       " '60978': 0.01024627685546875,\n",
       " '92319': 0.12261962890625,\n",
       " '58555': 0.009979248046875,\n",
       " '154186': 0.0019407272338867188,\n",
       " '148477': 0.0716552734375,\n",
       " '6': 0.0110626220703125,\n",
       " '122887': 0.002315521240234375,\n",
       " '8892': 0.01103973388671875,\n",
       " '17596': 0.0077362060546875,\n",
       " '29094': 0.01113128662109375,\n",
       " '6746': 0.01122283935546875,\n",
       " '74': 0.01128387451171875,\n",
       " '151152': 0.0341796875,\n",
       " '1398': 0.01102447509765625,\n",
       " '12465': 0.01122283935546875,\n",
       " '97109': 0.01113128662109375,\n",
       " '757': 0.01102447509765625,\n",
       " '5': 0.01108551025390625,\n",
       " '110156': 0.01325225830078125,\n",
       " '3775': 0.045745849609375,\n",
       " '1176': 0.007965087890625,\n",
       " '37755': 0.1085205078125,\n",
       " '27686': 0.01065826416015625,\n",
       " '7': 0.01117706298828125,\n",
       " '88591': 0.1160888671875,\n",
       " '11782': 0.10772705078125,\n",
       " '232': 0.0697021484375,\n",
       " '316': 0.042694091796875,\n",
       " '75693': 0.11834716796875,\n",
       " '390': 0.01073455810546875,\n",
       " '237': 0.011077880859375,\n",
       " '168360': 0.00615692138671875,\n",
       " '60212': 0.146240234375,\n",
       " '53702': 0.1529541015625,\n",
       " '581': 0.010986328125,\n",
       " '450': 0.0112152099609375,\n",
       " '88779': 0.046142578125,\n",
       " '5844': 0.01117706298828125,\n",
       " '164031': 0.09832763671875,\n",
       " '7401': 0.145751953125,\n",
       " '276': 0.016021728515625,\n",
       " '149201': 0.08697509765625,\n",
       " '3934': 0.0067291259765625,\n",
       " '36716': 0.07403564453125,\n",
       " '82451': 0.005756378173828125,\n",
       " '38043': 0.1378173828125}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for element in tqdm(ds):\n",
    "    element[col_name] = json.loads(element[col_name])\n",
    "\n",
    "raw_vectors = [element[col_name] for element in ds]\n",
    "raw_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "Columns:  {'_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'bge_m3_sparse_vector': Value(dtype='string', id=None)}\n",
      "Uploading data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee50b40a21b40b1b4e3235607b7baf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_data(dataset_name: str):\n",
    "    ds = load_dataset(f\"nirantk/{dataset_name}\", split=\"corpus\")\n",
    "    print(\"Columns: \", ds.features)\n",
    "    ds = ds.to_list()\n",
    "    return ds\n",
    "\n",
    "def to_points(ds: Dataset) -> Iterable[models.PointStruct]:\n",
    "    for element in tqdm(ds):\n",
    "        yield models.PointStruct(\n",
    "                id=int(element[\"_id\"]),\n",
    "                vector={col_name: convert_sparse_vector(json.loads(element[col_name]))},\n",
    "                payload={\n",
    "                    \"text\": element[\"text\"],\n",
    "                    \"title\": element[\"title\"],\n",
    "                    \"id\": element[\"_id\"],\n",
    "                },\n",
    "            )\n",
    "\n",
    "\n",
    "# if collection does not exist, create it\n",
    "if not client.collection_exists(collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},\n",
    "        sparse_vectors_config={\n",
    "            col_name: models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams(on_disk=False)\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def batch_iterator(iterable, batch_size=128):\n",
    "    \"\"\"\n",
    "    Iterates over an iterable in batches of a given size.\n",
    "\n",
    "    Args:\n",
    "        iterable: An iterable object.\n",
    "        batch_size: The size of each batch.\n",
    "\n",
    "    Yields:\n",
    "        A batch of items from the iterable.\n",
    "    \"\"\"\n",
    "\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield iterable[ndx : min(ndx + batch_size, l)]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "for batch in batch_iterator(range(10), 12):\n",
    "    print(batch)\n",
    "\n",
    "# Run ONCE to upload data, only when collection is empty\n",
    "if is_empty(client, collection_name):\n",
    "    ds = read_data(dataset_name)\n",
    "    points = to_points(ds)\n",
    "    print(\"Uploading data\")\n",
    "    client.upload_points(\n",
    "        collection_name=collection_name,\n",
    "        points=to_points(ds)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"../data/{canonical_dataset_name}/qrels/test.tsv\", sep=\"\\t\")\n",
    "test[\"query-id\"] = test[\"query-id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>873</td>\n",
       "      <td>1180972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>873</td>\n",
       "      <td>19307912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>873</td>\n",
       "      <td>27393799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>873</td>\n",
       "      <td>29025270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>873</td>\n",
       "      <td>3315558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query-id  corpus-id  score\n",
       "213       873    1180972      1\n",
       "214       873   19307912      1\n",
       "215       873   27393799      1\n",
       "216       873   29025270      1\n",
       "217       873    3315558      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"query-id\"].value_counts()\n",
    "test[test[\"query-id\"] == 873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"../data/{canonical_dataset_name}/queries.jsonl\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n",
    "\n",
    "# Only keep the test set queries\n",
    "queries = [q for q in queries if int(q[\"_id\"]) in list(test[\"query-id\"])]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " 'text': '0-dimensional biomaterials show inductive properties.',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a023950f1e4328971d14bd67c6330a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BGEM3FlagModel(\n",
    "    \"BAAI/bge-m3\", use_fp16=True\n",
    ")  # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "def get_sparse_vector(batch: List[str]):\n",
    "    output = model.encode(\n",
    "        batch, return_dense=False, return_sparse=True, return_colbert_vecs=False\n",
    "    )\n",
    "    return output[\"lexical_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 25/25 [00:04<00:00,  5.65it/s]\n"
     ]
    }
   ],
   "source": [
    "query_vectors = get_sparse_vector([q[\"text\"] for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors = [\n",
    "    models.SparseVector(\n",
    "        indices=query.keys(),\n",
    "        values=query.values(),\n",
    "    )\n",
    "    for query in query_vectors\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(indices=[106, 139217, 23, 17274, 765, 1563, 33176, 15853, 683, 40523, 2481, 5], values=[0.1339111328125, 0.2822265625, 0.13134765625, 0.25927734375, 0.11083984375, 0.1455078125, 0.19921875, 0.2161865234375, 0.2015380859375, 0.2188720703125, 0.11700439453125, 0.0173797607421875])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vectors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd49cb86e79d42bd802d11bde32b9e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit = 10\n",
    "results = []\n",
    "for qv in tqdm(query_vectors):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=models.NamedSparseVector(name=col_name, vector=qv),\n",
    "            with_payload=True,\n",
    "            limit=limit,\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(qv)\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids, doc_ids, ranks, scores = [], [], [], []\n",
    "for query, result in zip(queries, results):\n",
    "    query_id = query[\"_id\"]\n",
    "    result_ids = [str(r.id) for r in result]\n",
    "    result_scores = [r.score for r in result]\n",
    "    result_ranks = list(range(len(result)))\n",
    "    query_ids.extend(len(result) * [query_id])\n",
    "    doc_ids.extend(result_ids)\n",
    "    ranks.extend(result_ranks)\n",
    "    scores.extend(result_scores)\n",
    "    # print(f\"query: {query_id}\")\n",
    "    # print(f\"docid: {result_ids}\")\n",
    "    # print(f\"rank: {result_ranks}\")\n",
    "    # print(f\"score: {result_scores}\")\n",
    "\n",
    "run = {\n",
    "    \"query\": [int(q) for q in query_ids],\n",
    "    \"q0\": len(query_ids) * [\"q0\"],\n",
    "    \"docid\": doc_ids,\n",
    "    \"rank\": ranks,\n",
    "    \"score\": scores,\n",
    "    \"system\": len(query_ids) * [\"splade\"],\n",
    "}\n",
    "\n",
    "with open(\"bge-m3-lexical.run.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retokenize and Store that run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import Dict, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_sparse_tools import convert_sparse_vector\n",
    "from remap_tokens import (\n",
    "    aggregate_weights,\n",
    "    calc_tf,\n",
    "    filter_list_tokens,\n",
    "    filter_pair_tokens,\n",
    "    reconstruct_bpe,\n",
    "    rescore_vector,\n",
    "    snowball_tokenize,\n",
    "    stem_list_tokens,\n",
    "    stem_pair_tokens,\n",
    ")\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "reverse_vocab = {v: k for k, v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap raw vectors to weights and tokens\n",
    "corpus_sparse_vectors = []\n",
    "for element in raw_vectors:\n",
    "    tokens = list(element.keys())\n",
    "    tokens = [reverse_vocab[int(token)] for token in tokens]\n",
    "    sparse_vector = {\n",
    "        \"weights\": list(element.values()),\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    corpus_sparse_vectors.append(sparse_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaef342114948c1bd859788bea047d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retokenize_sparse_vector(text: str, source_sparse_vector: Dict[str, float], tokenizer: Tokenizer):\n",
    "    total_tokens_overall = 0\n",
    "    num_docs = 0\n",
    "    max_token_weight, num_tokens, total_tokens = {}, {}, 0\n",
    "\n",
    "    sequential_tokens = tokenizer.encode(text)\n",
    "    sequential_tokens = [reverse_vocab[t] for t in sequential_tokens]\n",
    "    reconstructed = reconstruct_bpe(enumerate(sequential_tokens))\n",
    "\n",
    "\n",
    "    # print(\"reconstructed:\\t\", reconstructed)\n",
    "\n",
    "    filtered_reconstructed = filter_pair_tokens(reconstructed)\n",
    "\n",
    "    # print(\"filtered:\\t\", filtered_reconstructed)\n",
    "\n",
    "    stemmed_reconstructed = stem_pair_tokens(filtered_reconstructed)\n",
    "\n",
    "    # print(\"stemmed:\\t\", stemmed_reconstructed)\n",
    "    # print(\"weights:\\t\", source_sparse_vector[\"weights\"])\n",
    "    weighed_reconstructed = aggregate_weights(\n",
    "        stemmed_reconstructed, source_sparse_vector[\"weights\"]\n",
    "    )\n",
    "\n",
    "    # print(\"weighted:\\t\", weighed_reconstructed)\n",
    "\n",
    "    total_tokens += len(weighed_reconstructed)\n",
    "    max_token_weight, num_tokens = {}, {}\n",
    "    for reconstructed_token, score in weighed_reconstructed:\n",
    "        max_token_weight[reconstructed_token] = max(\n",
    "            max_token_weight.get(reconstructed_token, 0), score\n",
    "        )\n",
    "        num_tokens[reconstructed_token] = num_tokens.get(reconstructed_token, 0) + 1\n",
    "\n",
    "    # print()\n",
    "    # tokens = stem_list_tokens(filter_list_tokens(snowball_tokenize(text)))\n",
    "    # total_tokens = len(tokens)\n",
    "    # num_tokens = Counter(tokens)\n",
    "    reweighted_sparse_vector = {}\n",
    "    token_score = rescore_vector(max_token_weight)\n",
    "    # print(\"token_score:\\t\", token_score)\n",
    "    for token, token_count in num_tokens.items():\n",
    "        score = token_score.get(token)\n",
    "        tf = score + token_count - 1\n",
    "        reweighted_sparse_vector[token] = calc_tf(tf, total_tokens)\n",
    "\n",
    "\n",
    "    total_tokens_overall += total_tokens\n",
    "    num_docs += 1\n",
    "    # print(len(reweighted_sparse_vector))\n",
    "    # print(\"reweighted_sparse_vector:\\t\", reweighted_sparse_vector)\n",
    "    # if not len(reweighted_sparse_vector) <= 1.2 * len(source_sparse_vector[\"tokens\"]):\n",
    "    #     print(reweighted_sparse_vector)\n",
    "    #     print(source_sparse_vector)\n",
    "    #     print(len(reweighted_sparse_vector), len(source_sparse_vector[\"tokens\"]))\n",
    "    #     raise ValueError(\"Something went wrong\")\n",
    "    return reweighted_sparse_vector\n",
    "\n",
    "\n",
    "reweighted_sparse_vectors = []\n",
    "for source_sparse_vector, text in tqdm(\n",
    "    zip(corpus_sparse_vectors, ds_raw[\"text\"]), total=len(corpus_sparse_vectors)\n",
    "):  \n",
    "    reweighted_sparse_vector = retokenize_sparse_vector(source_sparse_vector=source_sparse_vector, text=text, tokenizer=tokenizer)\n",
    "    # print(len(source_sparse_vectors))\n",
    "    reweighted_sparse_vectors.append(reweighted_sparse_vector)\n",
    "    # print(len(reweighted_sparse_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107., 158., 221.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find length of each sparse vector\n",
    "vector_lengths = [len(sv) for sv in reweighted_sparse_vectors]\n",
    "\n",
    "# Percentile of the lengths\n",
    "np.percentile(vector_lengths, [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_collection(client: QdrantClient, collection_name: str):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},\n",
    "        sparse_vectors_config={\n",
    "            col_name: models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams(on_disk=False)\n",
    "            )\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vocab of all keys in the reweighted sparse vectors\n",
    "vocab = set()\n",
    "for sv in reweighted_sparse_vectors:\n",
    "    vocab.update(sv.keys())\n",
    "\n",
    "# Convert this into a vocab object with each string having an id\n",
    "vocab = {word: i for i, word in enumerate(vocab)}\n",
    "invert_vocab = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035a23067bc141b6ba4f8ce0249a71da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recompute the reweighted sparse vectors with the new vocab\n",
    "id_reweighted_sparse_vectors = []\n",
    "for sv in tqdm(reweighted_sparse_vectors):\n",
    "    new_sv = {}\n",
    "    for word, weight in sv.items():\n",
    "        new_sv[vocab[word]] = weight\n",
    "    id_reweighted_sparse_vectors.append(new_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable: Iterable, n: int = 1) -> Iterable:\n",
    "    \"\"\"Yield successive n-sized chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf05a044b1ac42849e86b6d427181669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890b031cece14fdc9bdfc2d68039750f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def make_points(\n",
    "    reweighted_sparse_vectors: Dict, ds: Dataset\n",
    ") -> Iterable[models.PointStruct]:\n",
    "    points = []\n",
    "    for sv, element in tqdm(zip(reweighted_sparse_vectors, ds)):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(element[\"_id\"]),\n",
    "                vector={col_name: convert_sparse_vector(sv)},\n",
    "                payload={\n",
    "                    \"text\": element[\"text\"],\n",
    "                    \"title\": element[\"title\"],\n",
    "                    \"id\": element[\"_id\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return points\n",
    "\n",
    "collection_name = f\"{collection_name}-retok\"\n",
    "# next(read_data(id_reweighted_sparse_vectors, ds))\n",
    "reset_collection(client, collection_name)\n",
    "points = make_points(id_reweighted_sparse_vectors, ds)\n",
    "# Run ONCE to upload data, only when collection is empty\n",
    "for batch in tqdm(batched(points, 100)):\n",
    "    try:\n",
    "        client.upload_points(collection_name=collection_name, points=batch)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2288818359375,\n",
       " 0.046051025390625,\n",
       " 0.2142333984375,\n",
       " 0.17333984375,\n",
       " 0.271728515625,\n",
       " 0.10894775390625,\n",
       " 0.169677734375,\n",
       " 0.264404296875,\n",
       " 0.1953125,\n",
       " 0.209716796875,\n",
       " 0.060150146484375]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vectors[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_keyed_query_vectors = []\n",
    "for qv in query_vectors:\n",
    "    new_qv = {}\n",
    "    new_qv[\"weights\"] = qv.values\n",
    "    new_qv[\"tokens\"] = [reverse_vocab[i] for i in qv.indices]\n",
    "    wv_keyed_query_vectors.append(new_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': [0.2288818359375,\n",
       "  0.046051025390625,\n",
       "  0.2142333984375,\n",
       "  0.17333984375,\n",
       "  0.271728515625,\n",
       "  0.10894775390625,\n",
       "  0.169677734375,\n",
       "  0.264404296875,\n",
       "  0.1953125,\n",
       "  0.209716796875,\n",
       "  0.060150146484375],\n",
       " 'tokens': ['▁0',\n",
       "  '-',\n",
       "  'dimensional',\n",
       "  '▁bio',\n",
       "  'material',\n",
       "  's',\n",
       "  '▁show',\n",
       "  '▁induc',\n",
       "  'tive',\n",
       "  '▁properties',\n",
       "  '.']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_keyed_query_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe4f21da11741a284313d23f738c578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retokenize all the query tokens\n",
    "reweighted_query_tokens = []\n",
    "for qv, text in tqdm(zip(wv_keyed_query_vectors, [q[\"text\"] for q in queries])):\n",
    "    # print(text)\n",
    "    # print(qv)\n",
    "    reweighted_query_tokens.append(retokenize_sparse_vector(source_sparse_vector=qv, text=text, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59651e636f19414496cc32a5fde66193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/2000\n",
      "ordin\n",
      "▁alb\n",
      "▁galli\n",
      "▁gab\n",
      "mmel\n",
      "uer\n",
      "▁adept\n",
      "▁pola\n",
      "▁mata\n",
      "stes\n",
      "▁tira\n",
      "tiv\n",
      "▁casu\n"
     ]
    }
   ],
   "source": [
    "# Map the keys back to the original vocab with integer ids\n",
    "id_reweighted_query_tokens = []\n",
    "for qv in tqdm(reweighted_query_tokens):\n",
    "    new_qv = {}\n",
    "    for word, weight in qv.items():\n",
    "        try:\n",
    "            new_qv[vocab[word]] = weight    \n",
    "        except KeyError:\n",
    "            print(word)\n",
    "            continue\n",
    "    id_reweighted_query_tokens.append(new_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors = [\n",
    "    models.SparseVector(\n",
    "        indices=qv.keys(),\n",
    "        values=qv.values(),\n",
    "    )\n",
    "    for qv in id_reweighted_query_tokens\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadd6d6bbf50466396ba81f5f37b93fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit = 10\n",
    "results = []\n",
    "for qv in tqdm(qdrant_query_vectors):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=models.NamedSparseVector(name=col_name, vector=qv),\n",
    "            with_payload=True,\n",
    "            limit=limit,\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(qv)\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids, doc_ids, ranks, scores  = [], [], [], []\n",
    "for query, result in zip(queries, results):\n",
    "    query_id = query[\"_id\"]\n",
    "    result_ids = [str(r.id) for r in result]\n",
    "    result_scores = [r.score for r in result]\n",
    "    result_ranks = list(range(len(result)))\n",
    "    query_ids.extend(len(result) * [query_id])\n",
    "    doc_ids.extend(result_ids)\n",
    "    ranks.extend(result_ranks)\n",
    "    scores.extend(result_scores)\n",
    "    # print(f\"query: {query_id}\")\n",
    "    # print(f\"docid: {result_ids}\")\n",
    "    # print(f\"rank: {result_ranks}\")\n",
    "    # print(f\"score: {result_scores}\")\n",
    "\n",
    "run = {\n",
    "    \"query\": [int(q) for q in query_ids],\n",
    "    \"q0\": len(query_ids) * [\"q0\"],\n",
    "    \"docid\": doc_ids,\n",
    "    \"rank\": ranks,\n",
    "    \"score\": scores,\n",
    "    \"system\": len(query_ids) * [\"splade\"],\n",
    "}\n",
    "\n",
    "with open(\"bge-m3-retokenize-rescore.run.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightsplade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
