{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import Dict, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_sparse_tools import convert_sparse_vector\n",
    "from retokenize import (\n",
    "    aggregate_weights_idf,\n",
    "    reconstruct_bpe,\n",
    "    stem_words,\n",
    ")\n",
    "import sys\n",
    "from loguru import logger\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Disable debug logging\n",
    "\n",
    "logger.add(sys.stderr, level=\"INFO\")\n",
    "\n",
    "canonical_dataset_name = \"scifact\"\n",
    "dataset_name = \"scifact-bge-m3-sparse-vectors\"\n",
    "col_name = \"bge_m3_sparse_vector\"\n",
    "collection_name = f\"{dataset_name}-{col_name}-retok\"\n",
    "model_name = \"BAAI/bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"39176\": 0.1639404296875, \"21094\": 0.033599853515625, \"159958\": 0.1788330078125, \"119856\": 0.1939697265625, \"35011\": 0.1964111328125, \"26866\": 0.2216796875, \"70\": 0.011077880859375, \"168698\": 0.161865234375, \"14135\": 0.04254150390625, \"78574\": 0.1883544921875, \"831\": 0.051239013671875, \"52490\": 0.16845703125, \"8231\": 0.067626953125, \"70760\": 0.1358642578125, \"34754\": 0.1903076171875, \"136\": 0.01042938232421875, \"16750\": 0.024810791015625, \"23\": 0.01120758056640625, \"123309\": 0.1346435546875, \"164462\": 0.1981201171875, \"13315\": 0.131591796875, \"44954\": 0.168701171875, \"45755\": 0.1553955078125, \"92105\": 0.1864013671875, \"9\": 0.01116943359375, \"165598\": 0.1431884765625, \"297\": 0.010650634765625, \"214706\": 0.0733642578125, \"3332\": 0.016510009765625, \"191\": 0.01358795166015625, \"7154\": 0.00965118408203125, \"86898\": 0.06939697265625, \"177\": 0.0108184814453125, \"594\": 0.03509521484375, \"16625\": 0.197265625, \"16\": 0.0110626220703125, \"944\": 0.052734375, \"3956\": 0.0084228515625, \"1492\": 0.15283203125, \"4970\": 0.1644287109375, \"114137\": 0.157470703125, \"190659\": 0.030487060546875, \"72350\": 0.1312255859375, \"173676\": 0.300537109375, \"552\": 0.07379150390625, \"13\": 0.0109710693359375, \"24500\": 0.1395263671875, \"45964\": 0.0036983489990234375, \"4\": 0.011260986328125, \"74481\": 0.09429931640625, \"67\": 0.01102447509765625, \"35845\": 0.18408203125, \"1866\": 0.1240234375, \"991\": 0.059906005859375, \"29813\": 0.2294921875, \"53\": 0.01084136962890625, \"2256\": 0.07647705078125, \"2182\": 0.01110076904296875, \"17262\": 0.07257080078125, \"157955\": 0.11798095703125, \"109197\": 0.191162109375, \"479\": 0.11041259765625, \"32166\": 0.22314453125, \"15\": 0.0109710693359375, \"19\": 0.007411956787109375, \"2203\": 0.01097869873046875, \"729\": 0.07940673828125, \"4393\": 0.0728759765625, \"145048\": 0.2222900390625, \"49413\": 0.0479736328125, \"202120\": 0.0888671875, \"93425\": 0.1439208984375, \"111\": 0.0111846923828125, \"170176\": 0.2430419921875, \"2481\": 0.1390380859375, \"39395\": 0.0487060546875, \"700\": 0.08599853515625, \"41311\": 0.12744140625, \"209\": 0.048736572265625, \"3542\": 0.0108795166015625, \"22282\": 0.06719970703125, \"71\": 0.01125335693359375, \"10\": 0.01105499267578125, \"17932\": 0.0885009765625, \"1733\": 0.047821044921875, \"99\": 0.0111083984375, \"13579\": 0.1953125, \"9879\": 0.1702880859375, \"29459\": 0.1761474609375, \"1372\": 0.1883544921875, \"148\": 0.0596923828125, \"92\": 0.06829833984375, \"509\": 0.0100555419921875, \"11192\": 0.061279296875, \"79875\": 0.08502197265625, \"11948\": 0.08941650390625, \"39\": 0.01090240478515625, \"45792\": 0.00933074951171875, \"4432\": 0.08441162109375, \"227204\": 0.17333984375, \"154732\": 0.0090789794921875, \"47\": 0.0106964111328125, \"39225\": 0.162353515625, \"400\": 0.062408447265625, \"6492\": 0.047821044921875, \"70796\": 0.1552734375, \"150143\": 0.1650390625, \"4240\": 0.07659912109375, \"11044\": 0.072509765625, \"35066\": 0.0104217529296875, \"15044\": 0.01047515869140625, \"20028\": 0.01029205322265625, \"21373\": 0.086181640625, \"119475\": 0.008392333984375, \"231839\": 0.13818359375, \"77546\": 0.146728515625, \"20903\": 0.12060546875, \"42\": 0.01117706298828125, \"127319\": 0.1744384765625, \"678\": 0.0109405517578125, \"117396\": 0.025146484375, \"89931\": 0.130859375, \"3501\": 0.008514404296875, \"1914\": 0.12408447265625, \"91977\": 0.0919189453125, \"617\": 0.01123046875, \"615\": 0.010650634765625, \"1837\": 0.01062774658203125, \"194692\": 0.01126861572265625, \"89678\": 0.0265045166015625, \"1126\": 0.01122283935546875, \"915\": 0.0110321044921875, \"60978\": 0.01024627685546875, \"92319\": 0.12261962890625, \"58555\": 0.009979248046875, \"154186\": 0.0019407272338867188, \"148477\": 0.0716552734375, \"6\": 0.0110626220703125, \"122887\": 0.002315521240234375, \"8892\": 0.01103973388671875, \"17596\": 0.0077362060546875, \"29094\": 0.01113128662109375, \"6746\": 0.01122283935546875, \"74\": 0.01128387451171875, \"151152\": 0.0341796875, \"1398\": 0.01102447509765625, \"12465\": 0.01122283935546875, \"97109\": 0.01113128662109375, \"757\": 0.01102447509765625, \"5\": 0.01108551025390625, \"110156\": 0.01325225830078125, \"3775\": 0.045745849609375, \"1176\": 0.007965087890625, \"37755\": 0.1085205078125, \"27686\": 0.01065826416015625, \"7\": 0.01117706298828125, \"88591\": 0.1160888671875, \"11782\": 0.10772705078125, \"232\": 0.0697021484375, \"316\": 0.042694091796875, \"75693\": 0.11834716796875, \"390\": 0.01073455810546875, \"237\": 0.011077880859375, \"168360\": 0.00615692138671875, \"60212\": 0.146240234375, \"53702\": 0.1529541015625, \"581\": 0.010986328125, \"450\": 0.0112152099609375, \"88779\": 0.046142578125, \"5844\": 0.01117706298828125, \"164031\": 0.09832763671875, \"7401\": 0.145751953125, \"276\": 0.016021728515625, \"149201\": 0.08697509765625, \"3934\": 0.0067291259765625, \"36716\": 0.07403564453125, \"82451\": 0.005756378173828125, \"38043\": 0.1378173828125}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(f\"nirantk/{dataset_name}\", split=\"corpus\")\n",
    "ds[col_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = [json.loads(x) for x in ds[col_name]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change schema to Qdrant Sparse Vector\n",
    "\n",
    "1. Create vocab and reverse vocab from Tokenizer corresponding to the model\n",
    "2. Invert the integer index to token string\n",
    "3. Make lists from the keys and values of the vocab dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "vocab = tokenizer.get_vocab()\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vectors = []\n",
    "for sv in sparse_vectors:\n",
    "    raw_vectors.append(\n",
    "        {\n",
    "            \"tokens\": [reverse_vocab[int(key)] for key in sv.keys()],\n",
    "            \"weights\": list(sv.values()),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.',\n",
       " ['ance',\n",
       "  '‚ñÅimagin',\n",
       "  'g',\n",
       "  'M',\n",
       "  'RI',\n",
       "  ')',\n",
       "  'que',\n",
       "  'nce',\n",
       "  '‚ñÅten',\n",
       "  'sor',\n",
       "  '‚ñÅanalysis',\n",
       "  '‚ñÅapplied',\n",
       "  '‚ñÅmeasure',\n",
       "  '‚ñÅapparent',\n",
       "  '‚ñÅco',\n",
       "  'e',\n",
       "  'ffi',\n",
       "  'cient',\n",
       "  ',',\n",
       "  '‚ñÅcalcula'],\n",
       " [0.00965118408203125,\n",
       "  0.06939697265625,\n",
       "  0.0108184814453125,\n",
       "  0.03509521484375,\n",
       "  0.197265625,\n",
       "  0.0110626220703125,\n",
       "  0.052734375,\n",
       "  0.0084228515625,\n",
       "  0.15283203125,\n",
       "  0.1644287109375,\n",
       "  0.157470703125,\n",
       "  0.030487060546875,\n",
       "  0.1312255859375,\n",
       "  0.300537109375,\n",
       "  0.07379150390625,\n",
       "  0.0109710693359375,\n",
       "  0.1395263671875,\n",
       "  0.0036983489990234375,\n",
       "  0.011260986328125,\n",
       "  0.09429931640625])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"text\"][0], raw_vectors[0][\"tokens\"][30:50], raw_vectors[0][\"weights\"][30:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombine and Retokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alterations',\n",
       " 'architecture',\n",
       " 'cerebral',\n",
       " 'white',\n",
       " 'matter',\n",
       " 'the',\n",
       " 'developing',\n",
       " 'human',\n",
       " 'brain']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct_bpe(raw_vectors[0][\"tokens\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retokenize import aggregate_weights_idf_k_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd5bf88d82046f1923c5722d8ac2214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rescored_vectors = []\n",
    "# logger.level(\"DEBUG\")\n",
    "\n",
    "for source_sparse_vector in tqdm(raw_vectors):\n",
    "    reconstructed_words = reconstruct_bpe(source_sparse_vector[\"tokens\"])\n",
    "    # logger.debug(f\"Reconstructed words: {reconstructed_words}\")\n",
    "    stemmed_words = stem_words(reconstructed_words)\n",
    "    # logger.debug(f\"Stemmed words: {stemmed_words}\")\n",
    "    aggregated_weights = aggregate_weights_idf_k_b(stemmed_words, source_sparse_vector[\"tokens\"], source_sparse_vector[\"weights\"])\n",
    "    # logger.debug(f\"Aggregated weights: {aggregated_weights}\")\n",
    "    # break\n",
    "    rescored_vectors.append(aggregated_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 57.,  89., 137.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find length of each sparse vector\n",
    "vector_lengths = [len(sv) for sv in rescored_vectors]\n",
    "\n",
    "# Percentile of the lengths\n",
    "np.percentile(vector_lengths, [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rescored_vectors), rescored_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))\n",
    "\n",
    "def is_empty(client: QdrantClient, collection_name: str) -> bool:\n",
    "    return client.get_collection(collection_name).points_count == 0\n",
    "\n",
    "\n",
    "# client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_collection(client: QdrantClient, collection_name: str):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},\n",
    "        sparse_vectors_config={\n",
    "            col_name: models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams(on_disk=False)\n",
    "            )\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 4.696322767553414,\n",
       " 'line': 2.7630617011650673,\n",
       " 'develop': 1.8087965004176547,\n",
       " 'assess': 1.2705755599546529,\n",
       " 'toward': 0.9271178923354834,\n",
       " 'effect': 0.7608069946927775,\n",
       " 'term': 0.6545522287112017,\n",
       " '1.8': 0.5849347282303121,\n",
       " 'ed': 0.47280862491321196,\n",
       " 'coe': 0.4307592032305683,\n",
       " 'matter': 0.3953472334192463,\n",
       " 'greater': 0.36465045085821046,\n",
       " 'white': 0.33769936572737447,\n",
       " 'second': 0.3117835186054872,\n",
       " 'cortic': 0.2889593523727537,\n",
       " '1.15': 0.2727685155019938,\n",
       " 'imag': 0.25562374775164964,\n",
       " 'infant': 0.2397338007926837,\n",
       " 'cerebr': 0.22173821353555864,\n",
       " 'pre1.44': 0.20842428729570625,\n",
       " '01': 0.19613843543194556,\n",
       " 'absolut': 0.18461852642028495,\n",
       " 'reson': 0.1755500969703133,\n",
       " 'result': 0.16852661755142245,\n",
       " 'nonmi': 0.15896924343137298,\n",
       " 'relat': 0.15270517792085486,\n",
       " 'alter': 0.14698463541451465,\n",
       " '4.44': 0.14069510659227027,\n",
       " 'brain': 0.1357342488133793,\n",
       " 'aniso': 0.12791166259258735,\n",
       " 'anc': 0.12239143077056451,\n",
       " '06)': 0.11868991754738041,\n",
       " 'calcul': 0.11347850902274637,\n",
       " 'organ': 0.10591399154719697,\n",
       " 'time': 0.10266789398382671,\n",
       " 'ms': 0.0984091920214401,\n",
       " 'ri': 0.09539344084388482,\n",
       " 'preterm': 0.0906259367451952,\n",
       " 'posterior': 0.08810258700405184,\n",
       " 'differ': 0.0854731459858906,\n",
       " 'disabili': 0.0820812840704051,\n",
       " 'weight': 0.07949250260860388,\n",
       " 'magnet': 0.07596200375201634,\n",
       " 'insight': 0.07389495694916763,\n",
       " 'capsuleeffici': 0.07043182598704723,\n",
       " 'ural': 0.06714622904035257,\n",
       " '7)': 0.06574200442440772,\n",
       " 'the': 0.06265023286384938,\n",
       " 'studi': 0.06008394295149682,\n",
       " '17': 0.04709918539520472,\n",
       " 'live': 0.04504321105124289,\n",
       " 'comparedwhit': 0.04300476038382155,\n",
       " '2/': 0.04196277389929293,\n",
       " 'higher': 0.041042962002741885,\n",
       " 'visibl': 0.03926559043458063,\n",
       " 'intern': 0.03850606961308845,\n",
       " 'area': 0.037423078051364335,\n",
       " '3.0%,': 0.036534723610125344,\n",
       " 'wk': 0.03380470283240408,\n",
       " 'elin': 0.0320831286846122,\n",
       " 'earli': 0.03152321107573739,\n",
       " 'threedimension': 0.029940684700144382,\n",
       " 'que': 0.029309080376767858,\n",
       " 'high': 0.028672617891100035,\n",
       " '10': 0.028126135591179748,\n",
       " 'appli': 0.02650030041222841,\n",
       " '0.09': 0.025702574984163437,\n",
       " 'function': 0.02508614376039264,\n",
       " 'similar': 0.0245763763443698,\n",
       " '3.1': 0.022506943879587637,\n",
       " 'lower': 0.021796839139803792,\n",
       " '+/-': 0.02094531434806141,\n",
       " 'cient': 0.01825700034925917,\n",
       " 'ent': 0.016650818240831873,\n",
       " 'limb': 0.016424185048199005,\n",
       " 'microm': 0.015969713212078917,\n",
       " 'closer': 0.015717326955540283,\n",
       " '0.': 0.015520777944412126,\n",
       " 'm': 0.014030740215060806,\n",
       " 'affect': 0.013470354814681815,\n",
       " 'appar': 0.010978621138933711,\n",
       " 'architectur': 0.010385659808925217,\n",
       " 'trop': 0.009312594694354916,\n",
       " 'diffus': 0.007490561598627302,\n",
       " 'nce': 0.0049271809002862,\n",
       " 'tensor': 0.004009036603188798,\n",
       " '=': 0.003285136755607327,\n",
       " 'versus': 0.0032464221822267668,\n",
       " '-': 0.0031976750367422486,\n",
       " 'decreas': 0.003156447378348095,\n",
       " 'quantit': 0.0031203666152565825,\n",
       " 'birth': 0.0030681956545488592,\n",
       " 'gestat': 0.0030338041720230544,\n",
       " 'human': 0.0029960027611391107,\n",
       " 'ffi': 0.002961023162217599,\n",
       " 'relativ': 0.002928778962897751,\n",
       " 'full': 0.0028911839665013215,\n",
       " '28': 0.002850379540593248,\n",
       " 'fiber': 0.0028201893553891112,\n",
       " 'central': 0.0027925333159291403,\n",
       " 'water': 0.0027577221006967758,\n",
       " '0.6': 0.0027216759616053086,\n",
       " 'prematur': 0.0026806572699190376,\n",
       " 'measur': 0.0026497560460990582,\n",
       " '4.0': 0.002595367148014693,\n",
       " ')': 0.002560326182039999,\n",
       " 'callo': 0.002495035715963195,\n",
       " 'scan': 0.0024615444047376006,\n",
       " 'corpus': 0.00243757904132019,\n",
       " 'um': 0.0023857453048662072,\n",
       " 'p16)': 0.002310288966163962,\n",
       " 'analysi': 0.00219793183304316,\n",
       " '22.': 0.002106475390876317,\n",
       " ';': 0.002031963925490133,\n",
       " 'intostruct': 0.001889316082529056,\n",
       " ',': 0.0018531588183878594,\n",
       " 'show': 0.0018309251997234745,\n",
       " 'mean': 0.0016035620082661872,\n",
       " '(n': 0.0007935165422576042}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescored_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vocab of all keys in the reweighted sparse vectors\n",
    "vocab = set()\n",
    "for sv in rescored_vectors:\n",
    "    vocab.update(sv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58470"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into a vocab object with each string having an id\n",
    "vocab = {word: i for i, word in enumerate(vocab)}\n",
    "invert_vocab = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef526c2630f430ea3e37960e4ef844b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recompute the reweighted sparse vectors with the new vocab\n",
    "id_reweighted_sparse_vectors = []\n",
    "for sv in tqdm(rescored_vectors):\n",
    "    new_sv = {}\n",
    "    for word, weight in sv.items():\n",
    "        new_sv[vocab[word]] = weight\n",
    "    id_reweighted_sparse_vectors.append(new_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable: Iterable, n: int = 1) -> Iterable:\n",
    "    \"\"\"Yield successive n-sized chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219f216e75e94990acc8a34d754b52ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c114ffbe24980b851ae811e6b2d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_points(\n",
    "    reweighted_sparse_vectors: Dict, ds: Dataset\n",
    ") -> Iterable[models.PointStruct]:\n",
    "    points = []\n",
    "    for sv, element in tqdm(zip(reweighted_sparse_vectors, ds)):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(element[\"_id\"]),\n",
    "                vector={col_name: convert_sparse_vector(sv)},\n",
    "                payload={\n",
    "                    \"text\": element[\"text\"],\n",
    "                    \"title\": element[\"title\"],\n",
    "                    \"id\": element[\"_id\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return points\n",
    "\n",
    "\n",
    "# next(read_data(id_reweighted_sparse_vectors, ds))\n",
    "reset_collection(client, collection_name)\n",
    "points = make_points(id_reweighted_sparse_vectors, ds)\n",
    "# Run ONCE to upload data, only when collection is empty\n",
    "for batch in tqdm(batched(points, 100)):\n",
    "    try:\n",
    "        client.upload_points(collection_name=collection_name, points=batch)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"../data/{dataset_name}/qrels/test.tsv\", sep=\"\\t\")\n",
    "test[\"query-id\"] = test[\"query-id\"].astype(int)\n",
    "\n",
    "with open(f\"../data/{dataset_name}/queries.jsonl\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n",
    "\n",
    "# Only keep the test set queries\n",
    "queries = [q for q in queries if int(q[\"_id\"]) in list(test[\"query-id\"])]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"nirantk/splade-v3-lexical\")\n",
    "tokens = [tokenizer.encode(q[\"text\"]).tokens for q in queries]\n",
    "tokens = [list(set(t)) for t in tokens]\n",
    "# tokens = [list(set(t.ids)) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "tokens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign weight to all tokens and create a query vector with tokens and weights as keys\n",
    "query_vectors = []\n",
    "for token in tokens:\n",
    "    query_vector = {}\n",
    "    query_vector[\"tokens\"] = token\n",
    "    query_vector[\"weights\"] = [1] * len(token)\n",
    "    query_vectors.append(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retokenize all the query tokens\n",
    "reweighted_query_tokens = []\n",
    "for qv, text in tqdm(zip(query_vectors, [q[\"text\"] for q in queries])):\n",
    "    # print(text)\n",
    "    # print(qv)\n",
    "    reweighted_query_tokens.append(\n",
    "        retokenize_sparse_vector(\n",
    "            source_sparse_vector=qv, text=text, tokenizer=tokenizer\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reweighted_query_tokens[idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([len(t) for t in reweighted_query_tokens], [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the keys back to the original vocab with integer ids\n",
    "id_reweighted_query_tokens = []\n",
    "for qv in tqdm(reweighted_query_tokens):\n",
    "    new_qv = {}\n",
    "    for word, weight in qv.items():\n",
    "        try:\n",
    "            new_qv[vocab[word]] = weight\n",
    "        except KeyError:\n",
    "            print(word)\n",
    "            continue\n",
    "    id_reweighted_query_tokens.append(new_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors = [\n",
    "    models.SparseVector(\n",
    "        indices=qv.keys(),\n",
    "        values=qv.values(),\n",
    "    )\n",
    "    for qv in id_reweighted_query_tokens\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10\n",
    "results = []\n",
    "for qv in tqdm(qdrant_query_vectors):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=models.NamedSparseVector(name=col_name, vector=qv),\n",
    "            with_payload=True,\n",
    "            limit=limit,\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(qv)\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids, doc_ids, ranks, scores = [], [], [], []\n",
    "for query, result in zip(queries, results):\n",
    "    query_id = query[\"_id\"]\n",
    "    result_ids = [str(r.id) for r in result]\n",
    "    result_scores = [r.score for r in result]\n",
    "    result_ranks = list(range(len(result)))\n",
    "    query_ids.extend(len(result) * [query_id])\n",
    "    doc_ids.extend(result_ids)\n",
    "    ranks.extend(result_ranks)\n",
    "    scores.extend(result_scores)\n",
    "    # print(f\"query: {query_id}\")\n",
    "    # print(f\"docid: {result_ids}\")\n",
    "    # print(f\"rank: {result_ranks}\")\n",
    "    # print(f\"score: {result_scores}\")\n",
    "\n",
    "run = {\n",
    "    \"query\": [int(q) for q in query_ids],\n",
    "    \"q0\": len(query_ids) * [\"q0\"],\n",
    "    \"docid\": doc_ids,\n",
    "    \"rank\": ranks,\n",
    "    \"score\": scores,\n",
    "    \"system\": len(query_ids) * [\"splade\"],\n",
    "}\n",
    "\n",
    "with open(\"lexical-retokenize-rescore.run.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
