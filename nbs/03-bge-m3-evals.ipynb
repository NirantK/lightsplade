{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "canonical_dataset_name = \"scifact\"\n",
    "dataset_name = \"scifact-bge-m3-sparse-vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['_id', 'title', 'text', 'bge_m3_sparse_vector'],\n",
      "    num_rows: 5183\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(f\"nirantk/{dataset_name}\", split=\"corpus\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_eval = load(\"trec_eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Qrels and Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/lightsplade/lib/python3.9/site-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0],\n",
    "    \"q0\": [\"q0\"],\n",
    "    \"docid\": [\"doc_1\"],\n",
    "    \"rel\": [2]\n",
    "}\n",
    "run = {\n",
    "    \"query\": [0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"],\n",
    "    \"rank\": [0, 1],\n",
    "    \"score\": [1.5, 1.2],\n",
    "    \"system\": [\"test\", \"test\"]\n",
    "}\n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load reference Qrels from test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/{canonical_dataset_name}/qrels/test.tsv\", sep=\"\\t\")\n",
    "df.head()\n",
    "\n",
    "## Convert to qrel\n",
    "qrel = {\n",
    "    \"query\": [int(q) for q in df[\"query-id\"].tolist()],\n",
    "    \"q0\": [\"q0\"] * len(df),\n",
    "    \"docid\": [str(d) for d in df[\"corpus-id\"].tolist()],\n",
    "    \"rel\": df[\"score\"].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(predictions, references):\n",
    "    # Define expected fields and types for predictions and references\n",
    "    expected_pred_keys = {\n",
    "        'query': int, 'q0': str, 'docid': str, 'rank': int, 'score': float, 'system': str\n",
    "    }\n",
    "    expected_ref_keys = {\n",
    "        'query': int, 'q0': str, 'docid': str, 'rel': int\n",
    "    }\n",
    "\n",
    "    # Function to validate each record against expected fields and types\n",
    "    def check_record(record, expected_keys):\n",
    "        for key, expected_type in expected_keys.items():\n",
    "            if key not in record:\n",
    "                return f\"Missing key: {key}\"\n",
    "            if not all(isinstance(item, expected_type) for item in record[key]):\n",
    "                return f\"Incorrect type for key {key}, expected {expected_type}, got {type(record[key][0])}\"\n",
    "\n",
    "        # Check for consistent lengths across fields\n",
    "        length = len(record[next(iter(record))])  # get length of first item\n",
    "        if not all(len(value) == length for value in record.values()):\n",
    "            return \"Inconsistent lengths among fields\"\n",
    "\n",
    "        return \"Valid\"\n",
    "\n",
    "    # Validate predictions and references\n",
    "    pred_validation = check_record(predictions, expected_pred_keys)\n",
    "    ref_validation = check_record(references, expected_ref_keys)\n",
    "\n",
    "    return pred_validation, ref_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/lightsplade/lib/python3.9/site-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "with open(\"bge-m3-lexical.run.json\") as f:\n",
    "    run = json.load(f)\n",
    "\n",
    "# validate_data(run, qrel)\n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runid': 'splade',\n",
       " 'num_ret': 3000,\n",
       " 'num_rel': 339,\n",
       " 'num_rel_ret': 258,\n",
       " 'num_q': 300,\n",
       " 'map': 0.5812462962962962,\n",
       " 'gm_map': 0.05696682318679945,\n",
       " 'bpref': 0.0,\n",
       " 'Rprec': 0.49155555555555547,\n",
       " 'recip_rank': 0.5983492063492063,\n",
       " 'P@5': 0.15533333333333332,\n",
       " 'P@10': 0.086,\n",
       " 'P@15': 0.05733333333333332,\n",
       " 'P@20': 0.043,\n",
       " 'P@30': 0.02866666666666666,\n",
       " 'P@100': 0.0086,\n",
       " 'P@200': 0.0043,\n",
       " 'P@500': 0.00172,\n",
       " 'P@1000': 0.00086,\n",
       " 'NDCG@5': 0.6093764327586145,\n",
       " 'NDCG@10': 0.6315781437701369,\n",
       " 'NDCG@15': 0.6315781437701369,\n",
       " 'NDCG@20': 0.6315781437701369,\n",
       " 'NDCG@30': 0.6315781437701369,\n",
       " 'NDCG@100': 0.6315781437701369,\n",
       " 'NDCG@200': 0.6315781437701369,\n",
       " 'NDCG@500': 0.6315781437701369,\n",
       " 'NDCG@1000': 0.6315781437701369}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/lightsplade/lib/python3.9/site-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "with open(\"bge-m3-sentence-piece-retokenizer.run.json\") as f:\n",
    "    run = json.load(f)\n",
    "\n",
    "# validate_data(run, qrel)\n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runid': 'splade',\n",
       " 'num_ret': 2931,\n",
       " 'num_rel': 339,\n",
       " 'num_rel_ret': 1,\n",
       " 'num_q': 298,\n",
       " 'map': 0.0005592841163310962,\n",
       " 'gm_map': nan,\n",
       " 'bpref': 0.0,\n",
       " 'Rprec': 0.0,\n",
       " 'recip_rank': 0.0005592841163310962,\n",
       " 'P@5': 0.0,\n",
       " 'P@10': 0.00033557046979865775,\n",
       " 'P@15': 0.00022371364653243848,\n",
       " 'P@20': 0.00016778523489932888,\n",
       " 'P@30': 0.00011185682326621924,\n",
       " 'P@100': 3.3557046979865775e-05,\n",
       " 'P@200': 1.6778523489932888e-05,\n",
       " 'P@500': 6.7114093959731546e-06,\n",
       " 'P@1000': 3.3557046979865773e-06,\n",
       " 'NDCG@5': 0.0,\n",
       " 'NDCG@10': 0.0011953261312349739,\n",
       " 'NDCG@15': 0.0011953261312349739,\n",
       " 'NDCG@20': 0.0011953261312349739,\n",
       " 'NDCG@30': 0.0011953261312349739,\n",
       " 'NDCG@100': 0.0011953261312349739,\n",
       " 'NDCG@200': 0.0011953261312349739,\n",
       " 'NDCG@500': 0.0011953261312349739,\n",
       " 'NDCG@1000': 0.0011953261312349739}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
