{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_sparse_tools import convert_sparse_vector\n",
    "from remap_tokens import (\n",
    "    aggregate_weights,\n",
    "    calc_tf,\n",
    "    filter_list_tokens,\n",
    "    filter_pair_tokens,\n",
    "    reconstruct_sentence_piece,\n",
    "    rescore_vector,\n",
    "    snowball_tokenize,\n",
    "    stem_list_tokens,\n",
    "    stem_pair_tokens,\n",
    ")\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "canonical_dataset_name = \"scifact\"\n",
    "dataset_name = \"scifact-bge-m3-sparse-vectors\"\n",
    "source_col_name = col_name = \"bge_m3_sparse_vector\"\n",
    "collection_name = f\"{dataset_name}-{col_name}-retok\"\n",
    "model_name = \"BAAI/bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"39176\": 0.1639404296875, \"21094\": 0.033599853515625, \"159958\": 0.1788330078125, \"119856\": 0.1939697265625, \"35011\": 0.1964111328125, \"26866\": 0.2216796875, \"70\": 0.011077880859375, \"168698\": 0.161865234375, \"14135\": 0.04254150390625, \"78574\": 0.1883544921875, \"831\": 0.051239013671875, \"52490\": 0.16845703125, \"8231\": 0.067626953125, \"70760\": 0.1358642578125, \"34754\": 0.1903076171875, \"136\": 0.01042938232421875, \"16750\": 0.024810791015625, \"23\": 0.01120758056640625, \"123309\": 0.1346435546875, \"164462\": 0.1981201171875, \"13315\": 0.131591796875, \"44954\": 0.168701171875, \"45755\": 0.1553955078125, \"92105\": 0.1864013671875, \"9\": 0.01116943359375, \"165598\": 0.1431884765625, \"297\": 0.010650634765625, \"214706\": 0.0733642578125, \"3332\": 0.016510009765625, \"191\": 0.01358795166015625, \"7154\": 0.00965118408203125, \"86898\": 0.06939697265625, \"177\": 0.0108184814453125, \"594\": 0.03509521484375, \"16625\": 0.197265625, \"16\": 0.0110626220703125, \"944\": 0.052734375, \"3956\": 0.0084228515625, \"1492\": 0.15283203125, \"4970\": 0.1644287109375, \"114137\": 0.157470703125, \"190659\": 0.030487060546875, \"72350\": 0.1312255859375, \"173676\": 0.300537109375, \"552\": 0.07379150390625, \"13\": 0.0109710693359375, \"24500\": 0.1395263671875, \"45964\": 0.0036983489990234375, \"4\": 0.011260986328125, \"74481\": 0.09429931640625, \"67\": 0.01102447509765625, \"35845\": 0.18408203125, \"1866\": 0.1240234375, \"991\": 0.059906005859375, \"29813\": 0.2294921875, \"53\": 0.01084136962890625, \"2256\": 0.07647705078125, \"2182\": 0.01110076904296875, \"17262\": 0.07257080078125, \"157955\": 0.11798095703125, \"109197\": 0.191162109375, \"479\": 0.11041259765625, \"32166\": 0.22314453125, \"15\": 0.0109710693359375, \"19\": 0.007411956787109375, \"2203\": 0.01097869873046875, \"729\": 0.07940673828125, \"4393\": 0.0728759765625, \"145048\": 0.2222900390625, \"49413\": 0.0479736328125, \"202120\": 0.0888671875, \"93425\": 0.1439208984375, \"111\": 0.0111846923828125, \"170176\": 0.2430419921875, \"2481\": 0.1390380859375, \"39395\": 0.0487060546875, \"700\": 0.08599853515625, \"41311\": 0.12744140625, \"209\": 0.048736572265625, \"3542\": 0.0108795166015625, \"22282\": 0.06719970703125, \"71\": 0.01125335693359375, \"10\": 0.01105499267578125, \"17932\": 0.0885009765625, \"1733\": 0.047821044921875, \"99\": 0.0111083984375, \"13579\": 0.1953125, \"9879\": 0.1702880859375, \"29459\": 0.1761474609375, \"1372\": 0.1883544921875, \"148\": 0.0596923828125, \"92\": 0.06829833984375, \"509\": 0.0100555419921875, \"11192\": 0.061279296875, \"79875\": 0.08502197265625, \"11948\": 0.08941650390625, \"39\": 0.01090240478515625, \"45792\": 0.00933074951171875, \"4432\": 0.08441162109375, \"227204\": 0.17333984375, \"154732\": 0.0090789794921875, \"47\": 0.0106964111328125, \"39225\": 0.162353515625, \"400\": 0.062408447265625, \"6492\": 0.047821044921875, \"70796\": 0.1552734375, \"150143\": 0.1650390625, \"4240\": 0.07659912109375, \"11044\": 0.072509765625, \"35066\": 0.0104217529296875, \"15044\": 0.01047515869140625, \"20028\": 0.01029205322265625, \"21373\": 0.086181640625, \"119475\": 0.008392333984375, \"231839\": 0.13818359375, \"77546\": 0.146728515625, \"20903\": 0.12060546875, \"42\": 0.01117706298828125, \"127319\": 0.1744384765625, \"678\": 0.0109405517578125, \"117396\": 0.025146484375, \"89931\": 0.130859375, \"3501\": 0.008514404296875, \"1914\": 0.12408447265625, \"91977\": 0.0919189453125, \"617\": 0.01123046875, \"615\": 0.010650634765625, \"1837\": 0.01062774658203125, \"194692\": 0.01126861572265625, \"89678\": 0.0265045166015625, \"1126\": 0.01122283935546875, \"915\": 0.0110321044921875, \"60978\": 0.01024627685546875, \"92319\": 0.12261962890625, \"58555\": 0.009979248046875, \"154186\": 0.0019407272338867188, \"148477\": 0.0716552734375, \"6\": 0.0110626220703125, \"122887\": 0.002315521240234375, \"8892\": 0.01103973388671875, \"17596\": 0.0077362060546875, \"29094\": 0.01113128662109375, \"6746\": 0.01122283935546875, \"74\": 0.01128387451171875, \"151152\": 0.0341796875, \"1398\": 0.01102447509765625, \"12465\": 0.01122283935546875, \"97109\": 0.01113128662109375, \"757\": 0.01102447509765625, \"5\": 0.01108551025390625, \"110156\": 0.01325225830078125, \"3775\": 0.045745849609375, \"1176\": 0.007965087890625, \"37755\": 0.1085205078125, \"27686\": 0.01065826416015625, \"7\": 0.01117706298828125, \"88591\": 0.1160888671875, \"11782\": 0.10772705078125, \"232\": 0.0697021484375, \"316\": 0.042694091796875, \"75693\": 0.11834716796875, \"390\": 0.01073455810546875, \"237\": 0.011077880859375, \"168360\": 0.00615692138671875, \"60212\": 0.146240234375, \"53702\": 0.1529541015625, \"581\": 0.010986328125, \"450\": 0.0112152099609375, \"88779\": 0.046142578125, \"5844\": 0.01117706298828125, \"164031\": 0.09832763671875, \"7401\": 0.145751953125, \"276\": 0.016021728515625, \"149201\": 0.08697509765625, \"3934\": 0.0067291259765625, \"36716\": 0.07403564453125, \"82451\": 0.005756378173828125, \"38043\": 0.1378173828125}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(f\"nirantk/{dataset_name}\", split=\"corpus\")\n",
    "ds[col_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = [json.loads(x) for x in ds[source_col_name]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "vocab = tokenizer.get_vocab()\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombine and Retokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vectors = []\n",
    "for sv in sparse_vectors:\n",
    "    raw_vectors.append(\n",
    "        {\n",
    "            \"tokens\": [reverse_vocab[int(key)] for key in sv.keys()],\n",
    "            \"weights\": list(sv.values()),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e104d91ed764a46b9f28182f14bce98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retokenize_sparse_vector(text: str, source_sparse_vector: Dict[str, float], tokenizer: Tokenizer):\n",
    "    total_tokens_overall = 0\n",
    "    num_docs = 0\n",
    "    max_token_weight, num_tokens, total_tokens = {}, {}, 0\n",
    "\n",
    "    sequential_tokens = tokenizer.tokenize(text)\n",
    "    reconstructed = reconstruct_sentence_piece(sequential_tokens)\n",
    "\n",
    "    # print(\"reconstructed:\\t\", reconstructed)\n",
    "\n",
    "    filtered_reconstructed = filter_pair_tokens(reconstructed)\n",
    "\n",
    "    # print(\"filtered:\\t\", filtered_reconstructed)\n",
    "\n",
    "    stemmed_reconstructed = stem_pair_tokens(filtered_reconstructed)\n",
    "\n",
    "    # print(\"stemmed:\\t\", stemmed_reconstructed)\n",
    "    # print(\"weights:\\t\", source_sparse_vector[\"weights\"])\n",
    "    weighed_reconstructed = aggregate_weights(\n",
    "        stemmed_reconstructed, source_sparse_vector[\"weights\"]\n",
    "    )\n",
    "\n",
    "    # print(\"weighted:\\t\", weighed_reconstructed)\n",
    "\n",
    "    total_tokens += len(weighed_reconstructed)\n",
    "    max_token_weight, num_tokens = {}, {}\n",
    "    for reconstructed_token, score in weighed_reconstructed:\n",
    "        max_token_weight[reconstructed_token] = max(\n",
    "            max_token_weight.get(reconstructed_token, 0), score\n",
    "        )\n",
    "        num_tokens[reconstructed_token] = num_tokens.get(reconstructed_token, 0) + 1\n",
    "\n",
    "    # print()\n",
    "    # tokens = stem_list_tokens(filter_list_tokens(snowball_tokenize(text)))\n",
    "    # total_tokens = len(tokens)\n",
    "    # num_tokens = Counter(tokens)\n",
    "    reweighted_sparse_vector = {}\n",
    "    token_score = rescore_vector(max_token_weight)\n",
    "    # print(\"token_score:\\t\", token_score)\n",
    "    for token, token_count in num_tokens.items():\n",
    "        score = token_score.get(token)\n",
    "        tf = score + token_count - 1\n",
    "        reweighted_sparse_vector[token] = calc_tf(tf, total_tokens)\n",
    "\n",
    "\n",
    "    total_tokens_overall += total_tokens\n",
    "    num_docs += 1\n",
    "    # print(len(reweighted_sparse_vector))\n",
    "    # print(\"reweighted_sparse_vector:\\t\", reweighted_sparse_vector)\n",
    "    if not len(reweighted_sparse_vector) <= 1.2 * len(source_sparse_vector[\"tokens\"]):\n",
    "        print(reweighted_sparse_vector)\n",
    "        print(source_sparse_vector)\n",
    "        print(len(reweighted_sparse_vector), len(source_sparse_vector[\"tokens\"]))\n",
    "        raise ValueError(\"Something went wrong\")\n",
    "    return reweighted_sparse_vector\n",
    "\n",
    "\n",
    "reweighted_sparse_vectors = []\n",
    "for source_sparse_vector, text in tqdm(\n",
    "    zip(raw_vectors, ds[\"text\"]), total=len(raw_vectors)\n",
    "):  \n",
    "    reweighted_sparse_vector = retokenize_sparse_vector(source_sparse_vector=source_sparse_vector, text=text, tokenizer=tokenizer)\n",
    "    # print(len(source_sparse_vectors))\n",
    "    reweighted_sparse_vectors.append(reweighted_sparse_vector)\n",
    "    # print(len(reweighted_sparse_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30., 54., 85.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find length of each sparse vector\n",
    "vector_lengths = [len(sv) for sv in reweighted_sparse_vectors]\n",
    "\n",
    "# Percentile of the lengths\n",
    "np.percentile(vector_lengths, [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(reweighted_sparse_vectors), reweighted_sparse_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))\n",
    "\n",
    "\n",
    "def is_empty(client: QdrantClient, collection_name: str) -> bool:\n",
    "    return client.get_collection(collection_name).points_count == 0\n",
    "\n",
    "\n",
    "# client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_collection(client: QdrantClient, collection_name: str):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},\n",
    "        sparse_vectors_config={\n",
    "            col_name: models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams(on_disk=False)\n",
    "            )\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vocab of all keys in the reweighted sparse vectors\n",
    "vocab = set()\n",
    "for sv in reweighted_sparse_vectors:\n",
    "    vocab.update(sv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into a vocab object with each string having an id\n",
    "vocab = {word: i for i, word in enumerate(vocab)}\n",
    "invert_vocab = {i: word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df19de94b8c649af904c0b0d7abe6fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recompute the reweighted sparse vectors with the new vocab\n",
    "id_reweighted_sparse_vectors = []\n",
    "for sv in tqdm(reweighted_sparse_vectors):\n",
    "    new_sv = {}\n",
    "    for word, weight in sv.items():\n",
    "        new_sv[vocab[word]] = weight\n",
    "    id_reweighted_sparse_vectors.append(new_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable: Iterable, n: int = 1) -> Iterable:\n",
    "    \"\"\"Yield successive n-sized chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ce83280a0a449fa8a295167368523e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64b5f01424f4b3bacb5cf06506c2ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_points(\n",
    "    reweighted_sparse_vectors: Dict, ds: Dataset\n",
    ") -> Iterable[models.PointStruct]:\n",
    "    points = []\n",
    "    for sv, element in tqdm(zip(reweighted_sparse_vectors, ds)):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=int(element[\"_id\"]),\n",
    "                vector={col_name: convert_sparse_vector(sv)},\n",
    "                payload={\n",
    "                    \"text\": element[\"text\"],\n",
    "                    \"title\": element[\"title\"],\n",
    "                    \"id\": element[\"_id\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return points\n",
    "\n",
    "\n",
    "# next(read_data(id_reweighted_sparse_vectors, ds))\n",
    "reset_collection(client, collection_name)\n",
    "points = make_points(id_reweighted_sparse_vectors, ds)\n",
    "# Run ONCE to upload data, only when collection is empty\n",
    "for batch in tqdm(batched(points, 100)):\n",
    "    try:\n",
    "        client.upload_points(collection_name=collection_name, points=batch)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f\"../data/{canonical_dataset_name}/qrels/test.tsv\", sep=\"\\t\")\n",
    "test[\"query-id\"] = test[\"query-id\"].astype(int)\n",
    "\n",
    "with open(f\"../data/{canonical_dataset_name}/queries.jsonl\") as f:\n",
    "    queries = [json.loads(line) for line in f]\n",
    "\n",
    "# Only keep the test set queries\n",
    "queries = [q for q in queries if int(q[\"_id\"]) in list(test[\"query-id\"])]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d5b9f6e9e34411a3e29bf44237082f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BGEM3FlagModel(\n",
    "    \"BAAI/bge-m3\", use_fp16=True\n",
    ")  # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "def get_sparse_vector(batch: List[str]):\n",
    "    output = model.encode(\n",
    "        batch, return_dense=False, return_sparse=True, return_colbert_vecs=False\n",
    "    )\n",
    "    return output[\"lexical_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 25/25 [00:02<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 290 ms, total: 1.9 s\n",
      "Wall time: 2.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_query_vectors = get_sparse_vector([q[\"text\"] for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'3980': 0.1531,\n",
       "             '25388': 0.1818,\n",
       "             '7': 0.03915,\n",
       "             '57913': 0.147,\n",
       "             '34080': 0.0839,\n",
       "             '3038': 0.06354,\n",
       "             '112': 0.002756,\n",
       "             '8': 0.09863,\n",
       "             '180220': 0.1117,\n",
       "             '1409': 0.04636,\n",
       "             '11044': 0.131,\n",
       "             '199334': 0.2042,\n",
       "             '23417': 0.2339,\n",
       "             '40715': 0.2086,\n",
       "             '450': 0.03105,\n",
       "             '351': 0.0846,\n",
       "             '3284': 0.1382,\n",
       "             '10484': 0.08466})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 50\n",
    "raw_query_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_float_query_vectors(raw_query_vectors: List[Dict[str, float]]) -> List[Dict[str, List[float]]]:\n",
    "    float_query_vectors = []\n",
    "    for sv in raw_query_vectors:\n",
    "        new_sv = {}\n",
    "        new_sv[\"tokens\"] = list(sv.keys())\n",
    "        new_sv[\"weights\"] = [float(v) for v in sv.values()]\n",
    "        float_query_vectors.append(new_sv)\n",
    "    return float_query_vectors\n",
    "\n",
    "float_query_vectors = make_float_query_vectors(raw_query_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f760a417124439ca7061477f1aefefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reweighted_query_vectors = []\n",
    "for source_query_vector, text in tqdm(zip(float_query_vectors, [q[\"text\"] for q in queries])):\n",
    "    reweighted_qv = retokenize_sparse_vector(source_sparse_vector=source_query_vector, text=text, tokenizer=tokenizer)\n",
    "    reweighted_query_vectors.append(reweighted_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6., 12.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(t) for t in reweighted_query_vectors], [10, 50, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1.60583970427897,\n",
       " 'materi': 1.711582750511634,\n",
       " 'tive': 1.8413300733527267}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reweighted_query_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbcb646d83402c99f0cc23501d6a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/2000\n",
      "ordin\n",
      "▁difficil\n",
      "▁surviv\n",
      "▁surviv\n",
      "▁year\n",
      "▁perform\n",
      "mmel\n",
      "uer\n",
      "▁2.\n",
      "▁system\n",
      "▁diseas\n",
      "stes\n",
      "tiv\n"
     ]
    }
   ],
   "source": [
    "# Map the keys back to the original vocab with integer ids\n",
    "id_reweighted_query_tokens = []\n",
    "for qv in tqdm(reweighted_query_vectors):\n",
    "    new_qv = {}\n",
    "    for word, weight in qv.items():\n",
    "        try:\n",
    "            new_qv[vocab[word]] = weight    \n",
    "        except KeyError:\n",
    "            print(word)\n",
    "            continue\n",
    "    id_reweighted_query_tokens.append(new_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_vectors = [\n",
    "    models.SparseVector(\n",
    "        indices=qv.keys(),\n",
    "        values=qv.values(),\n",
    "    )\n",
    "    for qv in id_reweighted_query_tokens\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(indices=[2994, 4544, 2118, 2841, 4280, 1177, 1339, 243, 4701, 4436, 3322], values=[1.6690328878382839, 1.8074913885123627, 1.1815423365369104, 1.30626862811058, 1.379653324012354, 1.4625501566243453, 1.557535616122145, 1.1279511510106308, 1.2406559308186282, 1.0791091549313259, 1.0343905775447468])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_query_vectors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71df3d8520e4500a1fff08efe9ea952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit = 10\n",
    "results = []\n",
    "for qv in tqdm(qdrant_query_vectors):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=models.NamedSparseVector(name=col_name, vector=qv),\n",
    "            with_payload=True,\n",
    "            limit=limit,\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(qv)\n",
    "        results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids, doc_ids, ranks, scores  = [], [], [], []\n",
    "for query, result in zip(queries, results):\n",
    "    query_id = query[\"_id\"]\n",
    "    result_ids = [str(r.id) for r in result]\n",
    "    result_scores = [r.score for r in result]\n",
    "    result_ranks = list(range(len(result)))\n",
    "    query_ids.extend(len(result) * [query_id])\n",
    "    doc_ids.extend(result_ids)\n",
    "    ranks.extend(result_ranks)\n",
    "    scores.extend(result_scores)\n",
    "    # print(f\"query: {query_id}\")\n",
    "    # print(f\"docid: {result_ids}\")\n",
    "    # print(f\"rank: {result_ranks}\")\n",
    "    # print(f\"score: {result_scores}\")\n",
    "\n",
    "run = {\n",
    "    \"query\": [int(q) for q in query_ids],\n",
    "    \"q0\": len(query_ids) * [\"q0\"],\n",
    "    \"docid\": doc_ids,\n",
    "    \"rank\": ranks,\n",
    "    \"score\": scores,\n",
    "    \"system\": len(query_ids) * [\"bge-m3\"],\n",
    "}\n",
    "\n",
    "with open(\"bge-m3-sentence-piece-pair-rescore.run.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightsplade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
